
% --------------------------------------------------------------------------------
\subsection{Preface}
\cutdef*{subsubsection}
\label{section:tut:fullmonte:preface}

We warned at the beginning of the first series of tutorials that 
everything we said would be a lie.  And it was.

It is now time to begin confessing to those lies.

\cutend*


% --------------------------------------------------------------------------------
\subsection{Mythryl Functions:  Beyond Parameter Lists}
\cutdef*{subsubsection}

To date we have been fostering the illusion that Mythryl functions are much 
like functions in C or Perl, give or take the occasional syntactic oddity 
or feature.

In this section we draw aside the veil.

C functions are hardwired by the compiler to accept a 
comma-delimited sequence of parameters.  The C grammar specifies exactly 
what that parameter sequence may contain;  the C compiler translates 
directly from ordinal position within the parameter sequence to ordinal 
position within a stackframe.  As far as the C compiler is concerned, a 
function parameter list declaration is essentially an abstract specification 
of part of a function call stackframe.

The Mythryl compiler doesn't see function syntax that way at all.

To start with, the Mythryl compiler does not think of functions as having 
multiple parameters matching multiple arguments.  So far as the Mythryl 
compiler is concerned, every Mythryl function takes exactly one value 
as input and returns exactly one value as result.  (This turns out to make 
the compiler much simpler to write!)

What we have been presenting as a conventional function argument list,
the Mythryl compiler has all along been thinking of as {\it a single tuple 
argument}.

At first blush this may appear to be a purely philosophical distinction about 
as important to today's practicing programmer as is the distinction between 
\ahref{\homoiousian}{Homoiousian} and \ahref{\homoousian}{Homoousian} to 
today's practicing Christian.  (There was a time when confusing the two 
could get you killed!)

In fact, there is a world of difference between the two ways of thinking 
about the matter, and until you begin thinking about it the Mythryl way, 
you are not writing Mythryl at all, really, but rather writing C 
in Mythryl syntax.

Let us start with a simple example.  The fact that the Mythryl ``argument lists'' 
we have been writing are in fact tuple arguments means that we can construct 
such ``argument lists'' ahead of time, pass them around, and even store them 
in other datastructures, before finally applying the function to them.  Do not 
try any of these examples in C!

\begin{verbatim}
    #!/usr/bin/mythryl

    fun confess (name, condition) = {
        printf "Hello!  My name is %s and I am %s.\n"  name  condition;
    };

    confess( "Linus", "an open source programmer" );

    a = ( "Richard", "a free software author" );

    confess a;

    b = [ ( "Albert", "a physicist" ),
          ( "Karl",   "a mathematician" )
        ];

    map confess b;
\end{verbatim}

When run this produces

\begin{verbatim}
    linux$ ./my-script
    Hello!  My name is Linus and I am an open source programmer.
    Hello!  My name is Richard and I am a free software author.
    Hello!  My name is Albert and I am a physicist.
    Hello!  My name is Karl and I am a mathematician.
    linux$ 
\end{verbatim}

So already we can begin to see that this fresh way of thinking about functions 
is opening up fresh expressive possibilities for coding.

Now let us open up the world of possibilities a bit more.

The Mythryl compiler does not think of functions as accepting a single 
{\it tuple} as argument.  That is not what we said above.  The Mythryl 
compiler thinks of functions as accepting a single {\it value} as argument. 
Any type of of value will do.

In particular, the argument value handed to a function can just as easily 
be a record as a tuple.  The Mythryl compiler hardly distinguishes between 
the two anyhow;  to it a record is just a tuple with a teeny bit of extra 
icing on top.

This essentially means that we get functions with keyword arguments 
``for free'' in Mythryl, where some other languages devote just a 
remarkable amount of special-case jiggery-pokery logic in the compiler 
to implementing them:

\begin{verbatim}
    #!/usr/bin/mythryl

    fun confess { name, condition } = {
        printf "Hello!  My name is %s and I am %s.\n"  name  condition;
    };

    confess { name => "Linus", condition => "an open source programmer" };

    a = { name => "Richard", condition => "a free software author" };

    confess a;

    b = [ { name => "Albert", condition => "a physicist" },
          { name =>  "Karl", condition => "a mathematician" }
        ];

    map confess b;
\end{verbatim}

When run, this produces exactly the same results as the first script, and 
in fact may well compile into exactly the same binary code, but the 
readability impact is significant.  In particular, the intent behind 
the list of records is immediately much clearer to the reader than is that 
behind the earlier list of tuples.

Record arguments are particularly nice when a function has two 
arguments of the same type which might easily be confused.

For example when copying from one vector to another (say), 
the programming world has no consistent convention as to 
whether the destination should come first or second.  It 
is easy to get them backwards, and the result is an error 
which will not be caught at compiletime and which might 
take some time to track down at runtime.

Using record instead of tuple arguments can make the code 
clearer and reduce the risk of introducing errors during 
code maintenance:

\begin{verbatim}
    copy (        this_vector,        that_vector );    # Potentially confusing
    copy { src => this_vector, dst => that_vector };    # Much clearer.
\end{verbatim}

\cutend*


% --------------------------------------------------------------------------------
\subsection{Mythryl Functions:  Implicit Case Statements}
\cutdef*{subsubsection}

Let us return to our first {\it enum}-style {\tt Color} type declaration and 
the problem of printing out values of that type:

\begin{verbatim}
    #!/usr/bin/mythryl

    Color = RED | GREEN | BLUE;

    fun print_color color = {
        case color
        RED   => print "RED\n";
        GREEN => print "GREEN\n";
        BLUE  => print "BLUE\n";
        esac;
    };

    print_color RED;
    print_color GREEN;
    print_color BLUE;
\end{verbatim}

When run this of course produces

\begin{verbatim}
    linux$ ./my-script
    RED
    GREEN
    BLUE
\end{verbatim}

First off, note that we wrote {\tt print\_color RED;} above, not 
{\tt print\_color( RED );}.

Now that we know that Mythryl functions are not C functions, and can 
take any type of argument, we need no longer keep up the pretense that 
parentheses are associated with function invocation.  In Mythryl, 
parentheses are used for constructing tuples and for grouping; they 
have nothing whatever to do with function invocation.  Putting 
useless parentheses in function calls in Mythryl just makes you look 
like a beginner who is still writing C in Mythryl.

Now look at the above function definition.  It works just fine, but 
an experienced Mythryl programmer would rarely if ever write it that 
way.  Mythryl function syntax supports {\it implicit case statements} 
to allow writing such functions without an explicit {\tt case}, and 
an experienced Mythryl programmer would almost always automatically 
take advantage of that fact:

\begin{verbatim}
    #!/usr/bin/mythryl

    Color = RED | GREEN | BLUE;

    fun print_color RED   =>  print "RED\n";
        print_color GREEN =>  print "GREEN\n";
        print_color BLUE  =>  print "BLUE\n";
    end;

    print_color RED;
    print_color GREEN;
    print_color BLUE;
\end{verbatim}

When run, the above script will produce exactly the same output as the 
previous version, and in fact will probably compile into exactly the 
same binary code --- the first thing the Mythryl compiler does with such 
function syntax is to expand it into an explicit {\tt case} internally.

But what a difference in readability!  Seven lines of function definition 
have shrunk to four, and assymetric clutter has given way to pleasing 
symmetry.  The first version was rather ugly;  the second version is 
actually quite pretty!  (Always listen to your esthetic sense.  It is 
the voice of experience.  Beautiful code is better code.)

Now we are not only writing Mythryl code that works --- we are starting 
to write Mythryl code that {\it looks} like Mythryl code, code that an 
experienced Mythryl programmer might read without wincing.

\cutend*

% --------------------------------------------------------------------------------
\subsection{Mythryl Functions:  List Handling Idioms}
\cutdef*{subsubsection}

Let us return to the topic of functions which manipulate lists, and see 
how to write them in idiomatically correct Mythryl.

We have presented such functions previously in these tutorials, but 
they were written in a ``C written in Mythryl syntax'' style which 
would make any experienced Mythryl programmer wince.

Recall that the fundamental operator for constructing lists is the 
Mythryl '!' operator --- what Lisp calls {\tt cons}.  By repeatedly 
using '!' to prepend values to the empty list, we can build up any 
valid Mythryl list:

\begin{verbatim}
    linux$ my

    eval:  "abc" ! [];
    ["abc"]

    eval:  "abc" ! ("def" ! []);
    ["abc", "def"]

    eval:  "abc" ! ("def" ! ("ghi" ! []));
    ["abc", "def", "ghi"]
\end{verbatim}

Recall also that Mythryl functions allow pattern matching against 
arguments.

In fact, we now know that all the ``argument lists'' 
we have been using in our functions in the tutorials have really 
been extracting values from argument tuples via pattern 
matching.  (I warned you that pattern matching keeps popping up in 
Mythryl where you least expect it!)

Put those two facts together with our new knowledge that 
Mythryl functions may accept arguments of any type --- in particular, 
lists --- and that Mythryl function syntax can encode implicit 
{\tt case} statements, and we are now able to understand one of 
the list idioms dear to the Mythryl programmer's heart:

\begin{verbatim}
    #!/usr/bin/mythryl

    fun sum_list  list_of_integers
        =
        sum_it (list_of_integers, 0)
        where
            fun sum_it (    [], sum)  => sum;
                sum_it (i ! is, sum)  => sum_it( is, sum + i);
            end;
        end;

    printf "%d\n" (sum_list [1,2,3,4] );
\end{verbatim}

Running the above will give you:

\begin{verbatim}
    linux$ ./my-script
    10
\end{verbatim}

The above is a list-processing idiom that you will see over and over again, 
and if you write any significant amount of real Mythryl code, you will 
write it over and over again.

Three points to note:
\begin{itemize}

\item The {\tt where} syntax.

We could have written the above as 
the entirely equivalent  
\begin{verbatim}
    #!/usr/bin/mythryl

    fun sum_list  list_of_integers
        =
        {   fun sum_it (    [], sum)  => sum;
                sum_it (i ! is, sum)  => sum_it( is, sum + i);
            end;

            sum_it (list_of_integers, 0);
        };

    printf "%d\n" (sum_list [1,2,3,4] );
\end{verbatim}
but the preceding version is clearer because it motivates the 
{\tt sum\_it} function before it defines it, which makes it easier for the 
reader to understand why the function is being defined and thus how to interpret it.

\item The helper function idiom.

Lists are recursive datastructures, and recursive datastructure processing 
calls for recursive functions, but typically the recursive function doing 
the work needs extra result-so-far state arguments beyond those supplied 
by the original caller.

These leads to a bog-standard idiom in which the 
externally visible function is just a wrapper for the recursive function 
which does the work.

In the above example, the external caller supplied only the list 
argument, but to compute the sum we needed an extra argument 
containing the sum of the list values seen so far.

\item The {\tt [] / (i ! is)} list processing idiom.

Look again at the initial parameter patterns in the {\tt sum\_it} 
function:

\begin{verbatim}
            fun sum_it (    [], sum)  => sum;
                sum_it (i ! is, sum)  => sum_it( is, sum + i);
            end;
\end{verbatim}

The {\tt []} case detects end-of-iteration and returns the final result.

The {\tt i ! is} case (read as ``{\it \verb|'i'|} and more {\it \verb|'i'|}s'') pries one element 
off the start of the list; we process it, combine what we learn from 
it with one or more of our result-so-far state parameters, and then 
finish up by calling ourself recursively on the rest of the input list.
\end{itemize}

You will see this general pattern over and over again, until you can 
recognize it at a glance.

A frequent variation of it accumulates the result-so-far in a list. 
In this case, by the time we reach the terminating {\tt []} case on 
input, our result-so-far list is in the reverse order of of the 
original input list.  We have been taking values from the 
front of the input list and adding them to the front of the 
result list, so in the end the first value processed, derived from 
the first element of the input list, is now at the end of the 
result list.

Consequently, the {\tt []} case will almost always {\tt reverse} the 
result list before returning it:

\begin{verbatim}
    #!/usr/bin/mythryl

    fun list_to_upper  list_of_strings
        =
        f (list_of_strings, [])
        where
            fun f (    [], results_so_far)  => reverse results_so_far;
                f (s ! ss, results_so_far)  => f( ss, (string::to_upper s) ! results_so_far);
            end;
        end;

    map  (printf "%s\n") (list_to_upper [ "abc", "def", "ghi" ] );
\end{verbatim}

When run, the above produces

\begin{verbatim}
    linux$ ./my-script
    ABC
    DEF
    GHI
    linux$
\end{verbatim}

Note how the {\tt reverse} in the {\tt []} clause makes the results come out 
in the expected order.  

Note also how the helper function is this time simply called {\tt f}.  
I do not particularly approve of this idiom, but it is one you will 
see quite a bit in production Mythryl code, so it is good to get 
used to it.  It certainly has the virtue of brevity.

\cutend*


% --------------------------------------------------------------------------------
\subsection{Mythryl Functions:  Value Capture}
\cutdef*{subsubsection}

\begin{quote}\begin{tiny}
       ``You are full of surprises, Mr Baggins!.''\newline
         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~---{\em Gimli son of Gloin}
\end{tiny}\end{quote}

One will often see C code in which a function is passed around 
together with its argument.  Together they constitute a {\it 
fate}, a suspended computation which may be continued 
at any time by calling the function with its argument.

This arrangement is necessary in C because C functions are fixed 
at compile time, immutable at run time:  The only way to express 
a pending computation is to specify the code and state separately.

Mythryl allows the two to be neatly combined:

\begin{verbatim}
    #!/usr/bin/mythryl

    fun delayed_print  string
        =
        fn () = printf "%s\n" string;

    fate_a =  delayed_print "Just";
    fate_b =  delayed_print "another";
    fate_c =  delayed_print "Mythryl";
    fate_d =  delayed_print "hacker!";

    fate_a ();
    fate_b ();
    fate_c ();
    fate_d ();
\end{verbatim}

When run this produces

\begin{verbatim}
    linux$ ./my-script
    Just
    another
    Mythryl
    hacker!
    linux$ 
\end{verbatim}

What has happened here is that the anonymous functions ({\it thunk})s constructed 
by the {\tt \verb|fn () = printf "%s\n" string;|} line of code are {\it capturing} the 
{\tt string} arguments visible to them.

The Mythryl {\tt fn} statement is actually a {\it data constructor}!

In principle, if we really wanted to, we could write our programs 
constructing all of our datastructures entirely in terms of {\tt fn} 
statements capturing value, although the resulting code would not be 
very pleasant to read.  For example, we could constructs lists via 
a function which captures two values and returns a thunk capable of 
returning either on request.  Here is a slightly simplified example 
of such a function:

\begin{verbatim}
    #!/usr/bin/mythryl

    Selector = FIRST | SECOND;

    fun cons (a, b)
        =
        fn selector = case selector
                      FIRST  => a;
                      SECOND => b;
                      esac;

    x = cons( "abc", "def" );

    printf "%s\n" (x FIRST);
    printf "%s\n" (x SECOND);
\end{verbatim}

When run, the above yields:

\begin{verbatim}
    linux$ ./my-script
    abc
    def
    linux$ 
\end{verbatim}
     
Re-inventing the Mythryl list this way makes no sense, but using value 
capture to construct fates for later execution makes 
a lot of sense.  You will see this pervasively in production Mythryl 
code that you read, and after using this technique for awhile you will 
wonder how you ever programmed without it.

\cutend*

% --------------------------------------------------------------------------------
\subsection{Mythryl Functions:  Currying and Partial Application}
\cutdef*{subsubsection}

Let us return to the {\tt delayed\_print} function from the 
previous section:

\begin{verbatim}
    fun delayed_print  string
        =
        fn () = printf "%s\n" string;
\end{verbatim}

An alternate way to write that function and example in Mythryl is:

\begin{verbatim}
    #!/usr/bin/mythryl

    fun delayed_print  string  ()
        =
        printf "%s\n" string;

    fate_a =  delayed_print "Just";
    fate_b =  delayed_print "another";
    fate_c =  delayed_print "Mythryl";
    fate_d =  delayed_print "hacker!";

    fate_a ();
    fate_b ();
    fate_c ();
    fate_d ();
\end{verbatim}

When run, this produces exactly the same result as before:

\begin{verbatim}
    linux$ ./my-script
    Just
    another
    Mythryl
    hacker!
    linux$
\end{verbatim}

In fact, this example may well compile into bit-for-bit the same binary 
code as before.  The only difference is that now the {\tt fn} statement 
constructing the fate {\it thunk} is implicit rather than explicit. 

You may be tempted to think of the above {\tt delayed\_print} function as 
taking two arguments.  A better way --- the Mythryl way --- of thinking 
about the matter is that the above {\tt fun delayed\_print} statement 
defines a function of one argument (a string) which then returns another 
function of one (void) argument:  the fate {\it thunk}.

Thus, the api type declaration for such a function is

\begin{verbatim}
    delayed_print:  String -> (Void -> Void);
\end{verbatim}

Which is to say, handing a string to {\tt delayed\_print} gives you 
in return a function, which when given a {\it Void} argument {\tt ()} 
returns a void value.  (And in this case also prints something out, 
but the type system does not worry about that.)

Type arrows associate to the right, so in practice the above 
declaration is usually written without the parentheses:

\begin{verbatim}
    delayed_print:  String -> Void -> Void;
\end{verbatim}

That looks a little confusing at first, but you quickly get 
used to it after seeing it a few times --- and you will be 
seeing it a {\it lot} in Mythryl. 

Such function definitions are called {\it Curried} in honor of 
\ahref{\haskell}{Haskell Curry}, a functional programming pioneer 
widely admired for having a cool name.  (This kind of function 
definition was actually invented by 
\ahref{\schonfinkel}{Moses Ilyich Sch\"{o}nfinkel}, but nobody 
wants to talk about ``Sch\"{o}nfinkelled functions''.)

An expression like {\tt delayed\_print "Just";} above is referred to 
as a {\it partial application} of the {\tt delayed\_print} function, 
since its final result will not be produced until the final {\it Void} 
argument {\tt ()} is supplied.

Partial application of curried functions is a concise, convenient 
way to produce fates.  You will see this a lot in your 
reading of Mythryl code, and as you grow in proficiency as a 
Mythryl programmer you will find yourself taking advantage of this 
idiom steadily more frequently.

\cutend*


% --------------------------------------------------------------------------------
\subsection{Mythryl Functions:  Parsing Combinators I}
\cutdef*{subsubsection}
\label{section:tut:fullmonte:parsing-combinators-i}

In this section we take a short break from introducing new 
language features in order to show how to use currying, higher 
order functions, partial application, fates and infix 
notation to build  a concise recursive-descent backtracking parser. 

Combinator parsing is a pretty technique well worth learning 
in and of itself;  it is also an excellent exercise in simplifying 
code by thinking functionally.

Today parsers generated by tools like {\tt yacc} 
are usually used when generating parsers for programming 
languages.  However, recursive descent parsers still have 
advantages in fields like natural language processing, where 
the grammar may be not be LALR(1), or where it may be 
necessary to work with ambiguous grammars, returning all 
possible parses of a sentence and then using semantic 
constraints to select the most probable one.

Here are the parser rules for a small fragment of English:

\begin{verbatim}
    verb      =  match [ "eats", "throws", "eat", "throw" ];
    noun      =  match [ "boy", "girl", "apple", "ball"   ];
    article   =  match [ "the", "a"                       ];
    adjective =  match [ "big", "little", "good", "bad"   ];
    adverb    =  match [ "quickly", "slowly"              ];

    qualified_noun =   noun   |   adjective  &  noun;
    qualified_verb =   verb   |   adverb     &  verb;

    noun_phrase    =             qualified_noun
                   | article  &  qualified_noun;

    sentence
        =
        ( noun_phrase  &  qualified_verb  &  noun_phrase     # "The little boy quickly throws the ball"
        |                 qualified_verb  &  noun_phrase     # "Eat the apple"
        | noun_phrase  &  qualified_verb                     # "The girl slowly eats"
        |                 qualified_verb                     # "Eat"
        );
\end{verbatim}

That code is straight Mythryl, although it may not seem so 
at first glance.  To make those rules work, we must first 
define a few support functions.

We start by defining a binary-tree datastructure:

\begin{verbatim}
    Parsetree = PAIR (Parsetree, Parsetree)
              | TOKEN String
              ;
\end{verbatim}

This will hold the syntax tree generated by our parser.

As support we define a simple function to print out our parsetrees:

\begin{verbatim}
    fun parsetree_to_string (TOKEN string)
            =>
            string;

        parsetree_to_string (PAIR (parsetree1, parsetree2))
            =>
            sprintf "(%s %s)"
                (parsetree_to_string  parsetree1)
                (parsetree_to_string  parsetree2);
    end;
\end{verbatim}

The elements of our parser are parse functions, each 
of which attempts to match some pattern such as a verb phrase 
or noun phrase against part of the input string.  Our parse 
functions have the type

\begin{verbatim}
    Parse_Function
        =
        Success_Fate -> Failure_Fate -> List(String) -> Void;
\end{verbatim}

We use fate passing to handle backtracking:  We 
call the {\tt Success\_Fate} function if our parse function 
succeeds in matching its assigned pattern at the current location within 
the input text, otherwise we call the {\tt Failure\_Fate}.
The final {\tt List(String)} argument is the list of input 
tokens yet to be parsed.

The fate function types are:

\begin{verbatim}
    Failure_Fate
        =
        Void -> Void;

    Success_Fate
        =
        Parsetree            ->         # Parsetree for substring just matched.
        Failure_Fate ->
        List(String)         ->         # Input tokens not yet matched.
        Void;
\end{verbatim}

We begin with a parse function which attempts to match the next 
input token against a list of words:


\begin{verbatim}
    in = list::in;      # ``word in [ "abc", "def" ]'' is TRUE iff word == "abc" or word == "def".

    fun match  words  success_fate  failure_fate  []   : Void
            =>
            failure_fate  ();                                               # No token to match.

        match  words  success_fate  failure_fate (token ! tokens)
            =>
            if (string::to_lower(token) in words)

                 success_fate  (TOKEN token) failure_fate  tokens;
            else
                 failure_fate  ();                                          # Next token does not match.
            fi;     
    end;
\end{verbatim}

This function is reasonably straightforward.  If the next input token 
matches one of our words we construct a {\tt TOKEN} syntax tree 
node representing our successfully matched one-word syntax subtree 
and pass it to our {\tt success\_fate}, otherwise we call our 
{\tt failure\_fate}.

Next we define an "and" function which matches two patterns consecutively 
in the input.  This function takes as input two parse functions describing 
the subpatterns, and returns a parse function which will match their 
concatenation.

Because they build new parse functions by combining existing 
parse functions such 
functions are often called {\it combining forms}, or simply {\it 
combinators}.

The type of our combinator is

\begin{verbatim}
    (Parser, Parser) -> Parser 
\end{verbatim}

To improve the readability of our grammar rules, we 
use the infix operator {\tt \&} to name this function:

\begin{verbatim}
    fun parse_fn_1 & parse_fn_2
        =
        fn  success_fate
            =
            parse_fn_1
                (fn parsetree_1
                    =
                    parse_fn_2
                        (fn parsetree_2
                            =
                            success_fate  (PAIR (parsetree_1, parsetree_2))
                        )
                );
\end{verbatim}

This function is also quite straightforward.  We call 
{\tt parser\_1} with a success fate 
which calls {\tt parser\_2} 
with a success fate which constructs a syntax tree 
{\tt PAIR} node combining the two syntax subtrees they 
construct for it and then passes that {\tt PAIR} 
node to our own original success fate.

Note how we use partial application of curried functions 
to simplify the code.  Both {\tt parser\_1} and {\tt parser\_2} 
take more arguments than explicitly shown.  We could have 
written the same function as

\begin{verbatim}
    fun parse_fn_1 & parse_fn_2
        =
        fn  success_fate
            =
        fn  failure_fate
            =
        fn  tokens
            =
            parse_fn_1  success_fate_1  failure_fate  tokens
            where
                fun success_fate_1  parsetree_1  failure_fate  tokens
                    =
                    parse_fn_2  success_fate_2  failure_fate  tokens
                    where
                        fun success_fate_2  parsetree_2  failure_fate  tokens
                            =
                            success_fate  (PAIR (parsetree_1, parsetree_2))  failure_fate  tokens;
                    end;
            end;
\end{verbatim}

By using partial application we have cut our code in half.

Next we define a complementary "or" function which matches in the 
input either one of two given parse functions.  Once again, to 
improve readability, we give it a compact infix name instead of 
a conventional prefix alphabetic name:

\begin{verbatim}
    fun parse_fn_1 | parse_fn_2
        =
        fn  success_fate
            =
        fn  failure_fate
            =
        fn  tokens
            =
            parse_fn_1  success_fate_1  failure_fate_1  tokens
            where
                fun success_fate_1  parsetree   ignored_failure_fate  tokens
                    =
                    success_fate  parsetree   failure_fate  tokens;

                fun failure_fate_1 ()
                    =
                    parse_fn_2  success_fate  failure_fate  tokens;
            end;
\end{verbatim}

This function is much like the preceding one, except that here 
we synthesize a failure fate as well as a success fate.

We now have all the machinery in place for the grammar rule 
functions illustrated at the top of this section:

\begin{verbatim}
    verb      =  match [ "eats", "throws", "eat", "throw" ];
    noun      =  match [ "boy", "girl", "apple", "ball"   ];
    article   =  match [ "the", "a"                       ];
    adjective =  match [ "big", "little", "good", "bad"   ];
    adverb    =  match [ "quickly", "slowly"              ];

    qualified_noun =   noun   |   adjective  &  noun;
    qualified_verb =   verb   |   adverb     &  verb;

    noun_phrase    =             qualified_noun
                   | article  &  qualified_noun;

    sentence
        =
        ( noun_phrase  &  qualified_verb  &  noun_phrase     # "The little boy quickly throws the ball"
        |                 qualified_verb  &  noun_phrase     # "Eat the apple"
        | noun_phrase  &  qualified_verb                     # "The girl slowly eats"
        |                 qualified_verb                     # "Eat"
        );
\end{verbatim}

Note how we once again use partial application of curried functions 
to keep the code concise.  For example the first rule above can 
be written

\begin{verbatim}
    fun verb  success_fate  failure_fate  tokens
        =
        match [ "eats", "throws" ]  success_fate  failure_fate  tokens;
\end{verbatim}

but if we do that with all the rules they will be much 
harder to read and maintain.

Here are the final four functions needed to produce a functioning 
mini-parser for our fragment of English:

\begin{verbatim}
    fun parse string
        =
        sentence
            toplevel_success_fate
            toplevel_failure_fate
            (string_to_words  string)

         where

            fun toplevel_success_fate  parsetree  failure_fate  tokens
                =
                printf "Successful parse: %s\n" (parsetree_to_string  parsetree);


            fun toplevel_failure_fate  ()
                =
                print  "No parse found.\n";


            string_to_words =  string::tokens  char::is_space;
        end;
\end{verbatim}

Putting it all together, here is our complete parser package:

\begin{verbatim}
    package parse1 {

        in = list::in;

        Parsetree = PAIR (Parsetree, Parsetree)
                  | TOKEN String
                  ;

        fun parsetree_to_string (TOKEN string)
                =>
                string;

            parsetree_to_string (PAIR (parsetree1, parsetree2))
                =>
                sprintf "(%s %s)"
                    (parsetree_to_string  parsetree1)
                    (parsetree_to_string  parsetree2);
        end;



        # A parse function which matches any word in a given list:
        #
        fun match  words  success_fate  failure_fate  []   : Void
                =>
                failure_fate  ();                                               # No token to match.

            match  words  success_fate  failure_fate (token ! tokens)
                =>
                if (string::to_lower(token) in words)

                     success_fate  (TOKEN token) failure_fate  tokens;
                else
                     failure_fate  ();                                          # Next token does not match.
                fi;         
        end;


        # An 'and' parse combinator which requires that
        # the two given parse functions match successive
        # portions of the 'tokens' input:
        #
        fun parse_fn_1 & parse_fn_2
            =
            fn  success_fate
                =
                parse_fn_1
                    (fn parsetree_1
                        =
                        parse_fn_2
                            (fn parsetree_2
                                =
                                success_fate  (PAIR (parsetree_1, parsetree_2))
                            )
                    );


        # An 'or' parse combinator which requires that
        # one of the two given parse functions
        # match a prefix of 'tokens':
        #
        fun parse_fn_1 | parse_fn_2
            =
            fn  success_fate
                =
            fn  failure_fate
                =
            fn  tokens
                =
                parse_fn_1  success_fate_1  failure_fate_1  tokens
                where
                    fun success_fate_1  parsetree   ignored_failure_fate  tokens
                        =
                        success_fate  parsetree   failure_fate  tokens;

                    fun failure_fate_1 ()
                        =
                        parse_fn_2  success_fate  failure_fate  tokens;
                end;


        # Now a simple grammar for a small fragment of English:
        #
        verb      =  match [ "eats", "throws", "eat", "throw" ];
        noun      =  match [ "boy", "girl", "apple", "ball"   ];
        article   =  match [ "the", "a"                       ];
        adjective =  match [ "big", "little", "good", "bad"   ];
        adverb    =  match [ "quickly", "slowly"              ];

        qualified_noun =   noun   |   adjective  &  noun;
        qualified_verb =   verb   |   adverb     &  verb;

        noun_phrase    =             qualified_noun
                       | article  &  qualified_noun;

        sentence
            =
            ( noun_phrase  &  qualified_verb  &  noun_phrase     # "The little boy quickly throws the ball"
            |                 qualified_verb  &  noun_phrase     # "Eat the apple"
            | noun_phrase  &  qualified_verb                     # "The girl slowly eats"
            |                 qualified_verb                     # "Eat"
            );


        # Finally, a toplevel function to drive it all:
        #
        fun parse string
            =
            sentence
                toplevel_success_fate
                toplevel_failure_fate
                (string_to_words  string)

            where

                fun toplevel_success_fate  parsetree  failure_fate  tokens
                    =
                    printf "Successful parse: %s\n" (parsetree_to_string  parsetree);


                fun toplevel_failure_fate  ()
                    =
                    print  "No parse found.\n";


                string_to_words =  string::tokens  char::is_space;
            end;
    };
\end{verbatim}

This code is in {\tt src/app/tut/combinator-parsing/parse1.pkg} in the 
Mythryl source code distribution.  You may try it out by doing

\begin{verbatim}
    linux$ cd src/app/tut/combinator-parsing
    linux$ my
    eval:  make "parse1.lib";
    eval:  parse1::parse "The boy quickly throws the little ball";
    Successful parse: (((The boy) (quickly throws)) (the (little ball)))
\end{verbatim}

{\bf Further conciseness}:

At the risk of gilding the lily, recall that the Mythryl backticks 
operator is redefinable.  For example, we can do:

\begin{verbatim}
    linux$ my
    eval:  fun backticks__op string  =  string::tokens  char::is_space  string;
    eval:  `abc def`;

    ["abc", "def"]
\end{verbatim}

Of course, now that we are comfortable with partially applied 
curried functions, we are more likely to write just:

\begin{verbatim}
    linux$ my
    eval:  backticks__op  =  string::tokens  char::is_space;
    eval:  `abc def`;

    ["abc", "def"]
\end{verbatim}

Either way, this lets us replace

\begin{verbatim}
        verb      =  match [ "eats", "throws", "eat", "throw" ];
        noun      =  match [ "boy", "girl", "apple", "ball"   ];
        article   =  match [ "the", "a"                       ];
        adjective =  match [ "big", "little", "good", "bad"   ];
        adverb    =  match [ "quickly", "slowly"              ];
\end{verbatim}

by simply

\begin{verbatim}
        verb      =  match `eats throws eat throw`;
        noun      =  match `boy girl apple ball`;
        article   =  match `the a`;
        adjective =  match `big little good bad`;
        adverb    =  match `quickly slowly`;
\end{verbatim}

If we wrap {\tt match} into {\tt back\_\_ticks} by

\begin{verbatim}
    fun backticks__op string  =  match  (string::tokens char::is_space string);
\end{verbatim}

we can abbreviate further to just

\begin{verbatim}
        verb      =  `eats throws eat throw`;
        noun      =  `boy girl apple ball`;
        article   =  `the a`;
        adjective =  `big little good bad`;
        adverb    =  `quickly slowly`;
\end{verbatim}

Whether this is splendidly concise or dreadfully obscure 
depends on your taste and situation.  Mythryl gives you 
the tools;  how to use them is your decision.


{\bf Further reading}:

\begin{quotation}
\ahref{\evenhigherorderfunctionsforparsing}{Even Higher Order Functions for Parsing}\newline
\ahref{\higherorderfunctionsforparsing}{Higher Order Functions for Parsing}\newline
\end{quotation}

\cutend*

% --------------------------------------------------------------------------------
\subsection{Mythryl Functions:  Thunk Syntax}
\cutdef*{subsubsection}

When creating fates and callbacks, there are times 
when the standard

\begin{verbatim}
    fn () = 14;
\end{verbatim}

syntax is uncomfortably distracting.

For these cases Mythryl offers the alternative syntax

\begin{verbatim}
    {. 14; };
\end{verbatim}

That looks a little odd, but efficiently leads the reader's eye to focus 
on the important central expression rather than the surrounding syntactic 
noise.

The two forms are semantically entirely equivalent;  the compiler 
internally expands the latter to the former very early in processing.

Sometimes such microfunctions need parameters.  For example, often a sort 
routine will take as argument a comparison function defining the collating 
order:

\begin{verbatim}
    sort  (fn (a,b) = a < b)  [ 1, 2, 3 ];
\end{verbatim}

In such a context, the {\tt fn} syntax is again rather distracting. 
With a tip of the hat to Perl, Mythryl supports an abbreviation 
syntax here similar to that of the preceding case:

\begin{verbatim}
    sort  {. #a < #b; }  [ 1, 2, 3 ];
\end{verbatim}

The brevity of this form seems a better fit to the setting.

Again, the two versions of the syntax are entirely equivalent semantically, 
the compiler internally expanding the latter into the former very early in processing.

A prime motivation for the latter syntax was the desire to support iteration 
functions which may effectively be used in place of conventional loop syntax.

For example, the syntax

\begin{verbatim}
    foreach  (1..n)  fn i = {
        printf "%d\n" i;
    };
\end{verbatim}

is visually not particularly appealing;  a distinct improvement is obtained 
by substituting:

\begin{verbatim}
    foreach  (1..n)  {.
        printf "%d\n" #i;
    };
\end{verbatim}

The reader's eye now moves naturally to the significant 
content, largely undistracted by syntactic noise.


\cutend*

% --------------------------------------------------------------------------------
\subsection{Mythryl Functions:  Defaultable Keyword Parameters}
\cutdef*{subsubsection}

Mythryl draws its power from a few major design features which work together 
cleanly rather than many little features hacked together in {\it ad hoc} 
fashion.  Consequently, Mythryl often lack feature explicitly implemented 
by other languages, yet proves capable to achieving much the same results 
by sometimes unexpected application of more general mechanisms.

Function arguments with defaultable keyword parameters provide a case in 
point.  Sometimes a top-level api function takes a large number of potential 
options, but in practice almost all of them have a characteristic value which 
they take in the overwhelming majority of practical cases.  File-open commands, 
for example, may typically need just a filename, but have many other options 
occasionally useful.

Mythryl has no explicit function keyword argument defaulting mechanism.  In fact, 
it has no function keyword arguments at all as such, we just pass anonymous 
records to functions when we want that effect.

Here is one way to achieve that effect in Mythryl.

We first define the record to be received by the function in question, 
then a sumtype with one constructor for each defaultable keyword 
argument, and finally a helper function which translates an argument 
list of constructor-value pairs into the desired argument record.

The external caller provides a list of just the fields of interest as 
constructor-value pairs; the rest get default values during the 
translation; the function actually doing the work sees just the 
expected record argument.

Here's the code.  {\tt open\_file} is the external interface, 
{\tt hidden\_real\_open\_file\_fn} is the function doing the real work 
(here it just prints out its arguments), and {\tt diget\_keyword\_list} 
is the argument list translator:

\begin{verbatim}
    #!/usr/bin/mythryl

    Function_Keyword_Record
        =
        {    filename:               String,
             obscure_float_option:   Float,
             obscure_int_option:     Int,
             obscure_string_option:  String
        };

    Function_Keywords_Sumtype
        = FILENAME(              String )
        | OBSCURE_FLOAT_OPTION(  Float  )
        | OBSCURE_INT_OPTION(    Int    )
        | OBSCURE_STRING_OPTION( String )
        ;

    fun digest_keyword_list  keyword_list
        =
        {   filename              =  REF "default filename";   # Or whatever default value you like.
            obscure_float_option  =  REF 0.0;                  # "                                ".
            obscure_int_option    =  REF   0;                  # "                                ".
            obscure_string_option =  REF "";                   # "                                ".

            process_keywords  keyword_list
            where
                fun process_keywords []
                        =>
                        { filename              => *filename,
                          obscure_float_option  => *obscure_float_option,
                          obscure_int_option    => *obscure_int_option,
                          obscure_string_option => *obscure_string_option
                        };

                    process_keywords ((FILENAME string) ! rest)
                        =>
                        {   filename := string;
                            process_keywords rest;
                        };

                    process_keywords ((OBSCURE_FLOAT_OPTION f) ! rest)
                        =>
                        {   obscure_float_option := f;
                            process_keywords rest;
                        };

                    process_keywords ((OBSCURE_INT_OPTION i) ! rest)
                        =>
                        {   obscure_int_option := i;
                            process_keywords rest;
                        };

                    process_keywords ((OBSCURE_STRING_OPTION s) ! rest)
                        =>
                        {   obscure_string_option := s;
                            process_keywords rest;
                        };

                end;
            end;
        };

    fun hidden_real_open_file_fn  (r: Function_Keyword_Record)
        =
        {    # In a real application this is where
             # we would open the requested file.
             # For demo purposes, we just print
             # out the values in our argument record:
             #
             printf "real_fun:  r.filename              = %s\n" r.filename;
             printf "real_fun:  r.obscure_float_option  = %f\n" r.obscure_float_option;
             printf "real_fun:  r.obscure_int_option    = %d\n" r.obscure_int_option;
             printf "real_fun:  r.obscure_string_option = %s\n" r.obscure_string_option;
             printf "\n";
        };


    fun open_file  keyword_list
        =
        hidden_real_open_file_fn (digest_keyword_list  keyword_list);


    open_file [ FILENAME "myfile.txt" ];

    open_file [ FILENAME "myfile.txt",
                OBSCURE_STRING_OPTION "obscure"
              ];

    open_file [ FILENAME              "myfile.txt",
                OBSCURE_STRING_OPTION   "obscurer",
                OBSCURE_INT_OPTION         934146,
                OBSCURE_FLOAT_OPTION        251.2
              ];

\end{verbatim}

Running the above yields:

\begin{verbatim}
    linux$ ./my-script
    real_fun:  r.filename              = myfile.txt
    real_fun:  r.obscure_float_option  = 0.000000
    real_fun:  r.obscure_int_option    = 0
    real_fun:  r.obscure_string_option = 

    real_fun:  r.filename              = myfile.txt
    real_fun:  r.obscure_float_option  = 0.000000
    real_fun:  r.obscure_int_option    = 0
    real_fun:  r.obscure_string_option = obscure

    real_fun:  r.filename              = myfile.txt
    real_fun:  r.obscure_float_option  = 251.200000
    real_fun:  r.obscure_int_option    = 934146
    real_fun:  r.obscure_string_option = obscurer

    linux$
\end{verbatim}

The syntax to define such functions is clumsier than would be the 
case if the Mythryl compiler had a special hack to support this, but 
this is not a significant problem in practice since such functions 
are used relatively infrequently and are typically large enough 
that the extra overhead is not a serious concern.

The syntax to invoke such functions is quite concise and clear.

If you do not like the upper-case keywords {\sc SHOUTING AT YOU}, it is 
a trivial matter to write:

\begin{verbatim}
    filename              = FILENAME;
    obscure_float_option  = OBSCURE_FLOAT_OPTION;
    obscure_int_option    = OBSCURE_INT_OPTION;
    obscure_string_option = OBSCURE_STRING_OPTION;
\end{verbatim}

Thereafter you can instead write upper-case free calls like:

\begin{verbatim}
    open_file [ filename "myfile.txt" ];
    open_file [ filename "myfile.txt", obscure_string_option "obscure" ];
\end{verbatim}

These definitions can be made at either the package definition or package client end 
of things.  Whether they are an improvement is a matter of taste.

For a real-life example of this technique in use see 
\ahrefloc{src/opt/gtk/src/easy-gtk.pkg}{src/opt/gtk/src/easy-gtk.pkg}.


Notice that the above solution uses {\it side effects}, but that they are 
very benign, affecting reference cells which are only visible within 
{\tt digest\_keyword\_list} and which live only for the duration of one call to it. 
Even if two parallel threads running on separate cores were to invoke 
{\tt digest\_keyword\_list} simultaneously there would be no risk of 
race conditions or other destructive interactions.

If you are purist enough to dislike the solution even so, it is easily 
rewritten to eschew side effects:

\begin{verbatim}
    fun digest_keyword_list  keyword_list
        =
        process_keywords  (keyword_list, "default filename", 0.0, 0, "")
        where

            fun process_keywords ([], filename, obscure_float_option, obscure_int_option, obscure_string_option)
                    =>
                    # Done processing argument list, so
                    # construct and return equivalent
                    # argument record:
                    # 
                    { filename, obscure_float_option, obscure_int_option, obscure_string_option };


                process_keywords (((FILENAME s)              ! rest), filename, obscure_float_option, obscure_int_option, obscure_string_option)
                    =>
                    process_keywords (rest, s, obscure_float_option, obscure_int_option, obscure_string_option };


                process_keywords (((OBSCURE_FLOAT_OPTION f)  ! rest), filename, obscure_float_option, obscure_int_option, obscure_string_option)
                    =>
                    process_keywords (rest,  filename, f, obscure_int_option, obscure_string_option);


                process_keywords (((OBSCURE_INT_OPTION i)    ! rest), filename, obscure_float_option, obscure_int_option, obscure_string_option)
                    =>
                    process_keywords (rest, filename, obscure_float_option, i, obscure_string_option);


                process_keywords (((OBSCURE_STRING_OPTION s) ! rest), filename, obscure_float_option, obscure_int_option, obscure_string_option)
                    =>
                    process_keywords (rest,  filename, obscure_float_option, obscure_int_option, s);
            end;
        end;
\end{verbatim}

This is in most respects a more elegant solution.  The problem is that in a production 
application of the technique there might well be a hundred or more obscure options, resulting 
in very long {\tt process\_keywords} argument lists.  The resulting code would be both 
slower and harder to read.

Bottom line:  Sometimes the ``impure'' solution is the best one.  Engineering is no 
place for dogmatists.

(This is also an example of a situation in which it would be nice to have a {\it record 
update syntax} something like {\tt my\_record where field => value} which made a copy of 
a record with one field changed.  This is a frequently requested construct, and some 
variant of it is likely to get implemented one of these days.  Doing so would be a 
nice undergraduate class project and a welcome contribution.) 

\cutend*

% --------------------------------------------------------------------------------
\subsection{More Regular Expressions}
\cutdef*{subsubsection}
\label{section:tut:full-monte:regex}

Picking up where we \ahrefloc{section:tut:bare-essentials:regex}{left off}, 
we have seen how to do {\tt {\it string} \verb|=~| {\it regex}} matching and 
{\tt regex::replace\_all} substitutions;  it is time to explore some other 
functions exported by package \ahrefloc{pkg:regex}{regex} per the 
\ahrefloc{api:Regular\_Expression\_Matcher}{Regular\_Expression\_Matcher} api.

The {\tt regex::find\_first\_match\_to\_regex} function returns {\sc THE} first substring matching a regular expression, 
returning {\sc NULL} if no match is found:

\begin{verbatim}
    linux$ my
    eval:  regex::find_first_match_to_regex ./f.t/ "the fat father futzed";
    THE "fat"
\end{verbatim}

The {\tt regex::find\_all\_matches\_to\_regex} function returns all substrings matching a regular expression:

\begin{verbatim}
    linux$ my
    eval:  regex::find_all_matches_to_regex ./f.t/ "the fat father futzed";
    ["fat", "fat", "fut"]
\end{verbatim}

Thus, recalling that in Perl regular expressions {\tt \verb|\w|} matches word constituents 
and {\tt \verb|\b|} matches at word boundaries, one way to break out the words in a string is:

\begin{verbatim}
    linux$ my
    eval:  regex::find_all_matches_to_regex ./\b\w+\b/ "the fat father futzed";
    ["the", "fat", "father", "futzed"]
\end{verbatim}

Regular expressions use parentheses both for grouping expressions and also for 
designating substring matches of interest.  A number of {\tt regex} functions 
center on processing of such parenthesis-marked groupings. 

For example {\tt regex::find\_first\_groups\_all} matches a regular expression once against a 
string, raising exception {\sc NOT\_FOUND} if there is no match, otherwise returning the list 
of all substrings matching groups (parenthesized subexpressions):

\begin{verbatim}
    linux$ my

    eval:  regex::find_first_match_to_regex_and_return_all_groups ./f.q/ "the fat father futzed";
    NULL

    eval:  regex::find_first_match_to_regex_and_return_all_groups ./f.t/ "the fat father futzed";
    THE []

    eval:  regex::find_first_match_to_regex_and_return_all_groups ./(f)(.)(t)/ "the fat father futzed";
    THE ["f", "a", "t"]

    eval:  regex::find_first_match_to_regex_and_return_all_groups ./((f(.))t)/ "the fat father futzed";
    THE ["fat", "fa", "a"]
\end{verbatim}

Here:
\begin{itemize}
\item In the first example there was no match, so the call raised exception {\sc NOT\_FOUND}.

\item In the second example there was a match, but the regular expression contained 
no parenthesis-marked groupings, so the return list was empty.

\item In the third example the first match was against {\tt fat} and the regular 
expression had three sets of parentheses, so the returned list contained 
three strings, each corresponding to the substring matched by one 
regular expression parenthesis-pair.

\item The fourth example is just like the third except that the parentheses placements 
are different, and thus also the corresponding returned strings.
\end{itemize}

The {\tt regex::find\_first\_group {\it i}} function does the same as above, except that 
it returns only a single selected parenthesis group match, raising exception {\sc NOT\_FOUND} 
if the regex fails to match the string. 

By convention, group 0 is the complete matched string, hence {\tt regex::find\_first\_match\_to\_ith\_group 0 {\it regex}} 
is the same as {\tt regex::find\_first\_match\_to\_regex {\it regex}}:

\begin{verbatim}
    linux$ my

    eval:  regex::find_first_match_to_regex       ./(f)(.)(t)/ "the fat father futzed";
    THE "fat"

    eval:  regex::find_first_match_to_ith_group 0 ./(f)(.)(t)/ "the fat father futzed";
    THE "fat"

    eval:  regex::find_first_match_to_ith_group 1 ./(f)(.)(t)/ "the fat father futzed";
    THE "f"

    eval:  regex::find_first_match_to_ith_group 2 ./(f)(.)(t)/ "the fat father futzed";
    THE "a"

    eval:  regex::find_first_match_to_ith_group 3 ./(f)(.)(t)/ "the fat father futzed";
    THE "t"
\end{verbatim}

Hint:  There is no {\tt regex} call which explicitly returns the location 
of a match within a string, but it is easy to extract the leading string and 
compute its length.  For example, to find the location of the first "foo" in 
a string:

\begin{verbatim}
    eval:  strlen (regex::find_first_match_to_ith_group 1 ./^(.*)foo/ "the fool on the hill");
    THE 4
\end{verbatim}


The {\tt regex::find\_all\_matches\_to\_regex\_and\_return\_values\_of\_ith\_group {\it i}} function is the same as above, except that it 
returns the {\it i}-th parenthesis group match for all successful matches 
of the regular expression against the target string:

\begin{verbatim}
    eval:  regex::find_all_matches_to_regex_and_return_values_of_ith_group 2 ./(f)(.)(t)/ "the fat father futzed";
    ["a", "a", "u"]
\end{verbatim}

Finally, the {\tt regex::find\_all\_matches\_to\_regex\_and\_return\_all\_values\_of\_all\_groups} does the obvious:
\begin{verbatim}
    eval:  regex::find_all_matches_to_regex_and_return_all_values_of_all_groups ./(f)(.)(t)/ "the fat father futzed";
    [["f", "a", "t"], ["f", "a", "t"], ["f", "u", "t"]]
\end{verbatim}


We've already seen that {\tt regex::replace\_all} may be used to substitute 
a string for every regular expression match in a string:

\begin{verbatim}
    linux$ my

    eval:  regex::replace_all ./f.t/ "FAT" "the fat father futzed";
    "the FAT FATher FATzed"
\end{verbatim}

There is a matching call which replaces only the first match:

\begin{verbatim}
    linux$ my

    eval:  regex::replace_first ./f.t/ "FAT" "the fat father futzed";
    "the FAT father futzed"
\end{verbatim}

There is also a matching pair of functions which allow arbitrary substitutions 
at each regular expression matchpoint in the string by calling a 
user-supplied function to compute the replacement string.

The {\tt regex::replace\_first\_via\_fn} will return the template string if there is 
no match, otherwise it calls the user-supplied function with 
a list of strings corresponding to the parenthesis group matchings:

\begin{verbatim}
    linux$ my

    eval: regex::replace_first_via_fn  ./(f.t)/  {. toupper (strcat #stringlist); }  "the fat father futzed";
    "the FAT father futzed"
\end{verbatim}

As you might expect {\tt regex::replace\_all\_via\_fn} is identical except that it splices 
in replacements for all substrings matched by the regular expression:

\begin{verbatim}
    linux$ my

    eval: regex::replace_all_via_fn ./(f.t)/ {. toupper (strcat #stringlist); }  "the fat father futzed";
    "the FAT FATher FUTzed"
\end{verbatim}



For the ultimate in flexibility, the  
{\tt regex::regex\_case} function provides a 'case' 
type statement driven by regular expression 
pattern-matching.

The arguments consist of a text to be matched 
followed by a list of ({\it regex, action-fn}) pairs 
and a default action function.

Execution consists of matching each regex 
in order against the target text until one matches, 
at which point the corresponding action 
is invoked (with the substrings obtained 
from the match) and the result returned.

If no regex matches, the default action 
is executed and the result returned.

In any event, exactly one action function 
invoked exactly once:

\begin{verbatim}
    #!/usr/bin/mythryl

    fun diagnose  target_text
        =
        regex::regex_case
            target_text
            {  cases =>    [ (./utilize/,                       fn _       = printf "This guy is verbose!\n"                      ),
                             (./weaponize/,                     fn _       = printf "This guy is from the Pentagon!\n"            ),
                             (./(\b[bcdfghjklmnpqrstvwxz]+\b)/, fn strings = printf "What is this '%s' word?!\n" (strcat strings) )
                           ],

               default =>  fn _ = printf "I can deduce nothing.\n"
            };

    diagnose  "We must utilize our utmost efforts.";
    diagnose  "We must weaponize the chalkboards.";
    diagnose  "The crwth is revolting!";
    diagnose  "We are the people!";
\end{verbatim}

When run, the above script produces:

\begin{verbatim}
    linux$ ./my-script
    This guy is verbose!
    This guy is from the Pentagon!
    What is this 'crwth' word?!
    I can deduce nothing.
    linux$
\end{verbatim}


See also: \ahrefloc{section:libref:perl5-regular-expressions:overview}{Perl5 Regular Expressions Library Reference}.\newline
See also: \ahrefloc{section:tut:recipe:regular-expressions}{regular expression recipes}.

\cutend*

% --------------------------------------------------------------------------------
\subsection{Typelocked Vectors}
\cutdef*{subsubsection}
\label{section:tut:full-monte:typelocked-vectors}

Picking up where we \ahrefloc{section:tut:delving-deeper:vectors}{left off}, 
the vanilla \ahrefloc{api:Vector}{Vector} and \ahrefloc{api:Rw\_Vector}{Rw\_Vector} 
apis support very flexible vector functionality, but this flexibility comes at 
a price.

In order to be able to hold values of any type, a \ahrefloc{pkg:vector}{vector} 
is implemented as a vector of pointers to the actual values.  This way the vector 
elements can be anything from 8-bit unsigned values to 64-bit floats to perhaps 
entire binary trees, images, symbol tables or relational database tables.

Consequently, every vector \ahrefloc{pkg:vector}{vector} or \ahrefloc{pkg:rw\_vector}{rw\_vector} 
element stored has the space overhead of the in-vector pointer plus any per-element space 
overhead due to the memory allocation subsystem implementation and memory alignment restrictions. 
In the case of a vector holding 64-bit floats, this may easily triple the amount of memory 
required;  in the case of a vector holding 8-bit unsigned values this may result in memory 
consumption an order of magnitude higher than optimum.

Constantly indirecting through these vector pointers also increases the CPU time overhead 
required for vector computations.

Most of the time these space and time overhead costs are of negligible practical importance, 
a more than justifiable price to pay for code simplicity and cleanliness.

But sometimes these costs are significant enough that is worth some increase in code 
complexity in order to reduce them.

For such times Mythryl provides a variety of {\it typelocked} vector implementations 
where by ``typelocked'' we mean specialized to a particular type of element. 
The \ahrefloc{api:Typelocked\_Vector}{Typelocked\_Vector} and 
 \ahrefloc{api:Typelocked\_Rw\_Vector}{Typelocked\_Rw\_Vector} apis define the 
interfaces for these implementations, which include 
\ahrefloc{pkg:vector\_of\_chars}{vector\_of\_chars},
\ahrefloc{pkg:vector\_of\_one\_byte\_unts}{vector\_of\_one\_byte\_unts},
\ahrefloc{pkg:vector\_of\_eight\_byte\_floats}{vector\_of\_eight\_byte\_floats},
\ahrefloc{pkg:rw\_vector\_of\_chars}{rw\_vector\_of\_chars},
\ahrefloc{pkg:rw\_vector\_of\_one\_byte\_unts}{rw\_vector\_of\_one\_byte\_unts} and 
\ahrefloc{pkg:rw\_vector\_of\_eight\_byte\_floats}{rw\_vector\_of\_eight\_byte\_floats} packages.

The typelocked vector apis are very similar to the vanilla vector apis;  often 
you will simply be able to substitute the appropriate typelocked vector package 
for the vanilla one and soldier on with increased space and time efficiency:

\begin{verbatim}
    linux$ my

    eval:  v = vector_of_one_byte_unts::from_list (map one_byte_unt::from_int [ 1, 2, 3, 4 ]);

    eval:  vector_of_one_byte_unts::get (v, 0);
    0wx1

    eval:  vector_of_one_byte_unts::get (v, 1);
    0wx2

    eval:  vector_of_one_byte_unts::get (v, 2);
    0wx3


    eval:  v = rw_vector_of_one_byte_unts::make_rw_vector( 4, 0wx0 );

    eval:  for (i = 0; i < 4; ++i)  printf "%d\n" (one_byte_unt::to_int (rw_vector_of_one_byte_unts::get(v,i)));
    0
    0
    0
    0

    eval:  rw_vector_of_one_byte_unts::set( v, 0, 0wx12 );
    eval:  rw_vector_of_one_byte_unts::set( v, 1, 0wx45 );

    eval:  for (i = 0; i < 4; ++i)  printf "%d\n" (one_byte_unt::to_int (rw_vector_of_one_byte_unts::get(v,i)));
    18
    69
    0
    0


    eval:  package fv = rw_vector_of_eight_byte_floats;

    eval:  v = fv::make_rw_vector( 4, 0.0 );

    eval:  for (i = 0; i < 4; ++i)  printf "%f\n" (rw_vector_of_eight_byte_floats::get(v,i));
    0.000000
    0.000000
    0.000000
    0.000000

    eval:  fv::set( v, 0, 3.141592 );
    eval:  fv::set( v, 1, 2.718281 );

    eval:  for (i = 0; i < 4; ++i)  printf "%f\n" (rw_vector_of_eight_byte_floats::get(v,i));
    3.141592
    2.718282
    0.000000
    0.000000
\end{verbatim}




\cutend*
% --------------------------------------------------------------------------------
\subsection{Vector Slices}
\cutdef*{subsubsection}
\label{section:tut:full-monte:vector-slices}

C has a very relaxed approach to typing, allowing one to synthesize a 
pointer to anywhere in memory and call it anything one likes via code 
like

\begin{verbatim}
    float* fp = (float*) 0x1245;
\end{verbatim}

This is often used to advantage in such situations as in writing 
memory allocators and garbage collectors, where typed values are 
appearing, moving and disappearing.

A typesafe language like Mythryl cannot be quite that relaxed about pointers. 
That is one reason the Mythryl garbage collector is written in C, not Mythryl.

C code also often uses pointer arithmetic to refer to a substring of a given string:

\begin{verbatim}
    char* long_string = "abcdefghijklmnopqrstuvwxyz";
    char* last_half   = long_string + 13;
\end{verbatim}

In Mythryl we can and do provide a functionally similar way to create 
and use references to substrings and subvectors.  Mythryl calls these 
references {\it slices}.

Apis supporting vector slicing include:
\begin{itemize}
\item \ahrefloc{api:Vector\_Slice}{Vector\_Slice}
\item \ahrefloc{api:Rw\_Vector\_Slice}{Rw\_Vector\_Slice}
\item \ahrefloc{api:Typelocked\_Vector\_Slice}{Typelocked\_Vector\_Slice}
\item \ahrefloc{api:Typelocked\_Rw\_Vector\_Slice}{Typelocked\_Rw\_Vector\_Slice}
\end{itemize}
The \ahrefloc{api:Substring}{Substring} api is closely related.

Packages implementing vector slices include:
\begin{itemize}
\item \ahrefloc{pkg:vector\_slice\_of\_chars}{vector\_slice\_of\_chars}
\item \ahrefloc{pkg:vector\_slice\_of\_eight\_byte\_floats}{vector\_slice\_of\_eight\_byte\_floats}
\item \ahrefloc{pkg:rw\_vector\_slice}\_of\_chars{rw\_vector\_slice\_of\_chars}
\item \ahrefloc{pkg:rw\_vector\_slice\_of\_eight\_byte\_floats}{rw\_vector\_slice\_of\_eight\_byte\_floats}
\item \ahrefloc{pkg:rw\_vector\_slice\_of\_one\_byte\_unts}{rw\_vector\_slice\_of\_one\_byte\_unts}
\item \ahrefloc{pkg:vector\_slice\_of\_one\_byte\_unts}{vector\_slice\_of\_one\_byte\_unts}
\end{itemize}

The \ahrefloc{pkg:substring}{substring} package is closely related.

Slices optimize time/space performance at the cost of increased code 
complexity.  Like all such optimizations, they should be used {\it only 
if you have working code which clearly has a substantial performance problem.} 
Absent that, it is better to just create new vectors as needed.

In general slices behave just like the underlying vectors once created:

\begin{verbatim}
    linux$ my

    eval:  vector = vector::from_list (0..9);
    #[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]

    eval:  package vs = vector_slice;                     # Short synonym.
    eval:  slice = vs::make_slice (vector, 5, THE 4);     # Offset 5, length 4.

    eval:  for (i = 0; i < vs::length slice; ++i)   printf "%d: %d\n" i (vs::get (slice, i));
    0: 5
    1: 6
    2: 7
    3: 8

    eval:  vs::to_vector slice;                           # Create new vector holding copy of slice contents.
    #[5, 6, 7, 8]
\end{verbatim}

For variety, here is the same example done with a slice of a {\tt float64\_vector}:

\begin{verbatim}
    linux$ my

    eval:  vector = vector_of_eight_byte_floats::from_list (map float64::from_int (0..9));
    #[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]

    eval:  package vs = vector_slice_of_eight_byte_floats;
    eval:  slice = vs::make_slice (vector, 5, THE 4);    # Create a slice pointing into above vector.

    eval:  for (i = 0; i < vs::length slice; ++i)  printf "%d: %f\n" i (vs::get (slice, i));
    0: 5.000000
    1: 6.000000
    2: 7.000000
    3: 8.000000

    eval:  vs::to_vector slice;                           # Create new vector holding copy of slice contents.
    #[5.0, 6.0, 7.0, 8.0]
\end{verbatim}

\cutend*



% --------------------------------------------------------------------------------
\subsection{Mythryl Types:  Hindley-Milner Type Inference}
\cutdef*{subsubsection}

The lack of explicit type declarations makes a Mythryl function definition like 

\begin{verbatim}
    fun next(arg) = arg+1;
\end{verbatim}

look a lot more like a similar declaration in an untyped scripting 
language like Python or Ruby than it does like the equivalent declaration 
in C, festooned with type declarations:

\begin{verbatim}
    int next (int arg) { return a+1; } 
\end{verbatim}

But Mythryl is in fact a strongly typed language --- more so than C, 
in fact --- and Mythryl syntax lets us, if we wish, festoon our function 
declarations with as many types as any C program.  The result even 
looks something like the above C case when we do so:

\begin{verbatim}
    fun sum (arg: Int): Int = { a+1; };
\end{verbatim}


Appearances to the contrary, from a typing point of view Mythryl code 
is in fact much more like C than like untyped scripting languages.

Like the C compiler, the Mythryl compiler statically computes a 
precise type for every variable, value, function and expression.

Like the C compiler, the Mythryl compiler takes advantage of type 
information for such things as deciding when to generate 
floating-point arithmetic instructions and when to generate integer 
arithmetic instructions.

The critical difference is that C has a very simple, {\it ad hoc} 
type system design dating from the 1960s, whereas Mythryl uses a 
sophisticated modern type system designed around \ahref{\hindleymilner}{{\it Hindley-Milner}} type inference.

Hindley-Milner type inference 
(also known as {\it Damas-Milner} type inference) is based upon the 
\ahref{\unification}{{\it unification}} operation 
popularized by Prolog.  Consequently writing type declarations in Mythryl is a bit 
like writing Prolog code;  as we shall see subsequently, it is possible 
to write pages of useful Mythryl code entirely as type definitions.

The more immediately interesting aspect of Mythryl type inference is that 
the compiler freely propagates type inferences outward through the source 
code from every source of information.

The easiest way to explore Mythryl typing is to use its interactive mode 
with result type display turned on:

\begin{verbatim}
    linux$ my
    eval:  set_control  "mythryl_parser::show_interactive_result_types" "TRUE";

    eval:  2+2;

    4 : Int

    eval:  fun sum(a,b) = a+b;

    fn : (Int, Int) -> Int

    eval:  fun swap(a,b) = (b,a);

    fn : (X, Y) -> (Y, X)

\end{verbatim}

The remainder of this section presumes that you have turned on 
result type display as shown above.

Suppose for example that you enter

\begin{verbatim}
    eval:  fun next (arg) = arg + 1.0;

    fn : Float -> Float
\end{verbatim}

The Mythryl declaration of the overloaded addition operator in 
\ahrefloc{src/lib/core/init/pervasive.pkg}{src/lib/core/init/pervasive.pkg} 
declares that it combines two values of the same type to produce another 
value of the same type:

\begin{verbatim}
    overloaded my + :   ((X, X) -> X)
\end{verbatim}

The Mythryl compiler knows that constant {\tt 1.0} is of type {\tt Float}, 
hence it can deduce that {\tt arg} must also be a {\tt Float}, and so 
must the result of the addition and consequently of the function, so 
that function {\tt next} must necessarily take a {\tt Float} argument 
and return a {\tt Float} result, giving it a type of {\tt Float -> Float}. 

If we instead enter

\begin{verbatim}
    eval:  fun next(arg) = arg + "1";

    fn : String -> String
\end{verbatim}

exactly the same chain of reasoning leads the compiler to deduce a type 
of {\tt String -> String} for our function.

It is due to the power of this style of type inference that Mythryl code can 
be written largely without explicit types.  The major exception is api 
definitions.  Api definitions represent interfaces to unknown external code 
so one needs to explicitly specify all types in an {\tt .api} file. 
(It is in any event good documentation to do so.) 

Another place where type inference often fails is when setting a variable to 
an empty list:

\begin{verbatim}
    result_list = [];
\end{verbatim}

In such cases, the Mythryl compiler often has no idea whether you intend {\tt result\_list} 
to be a list of integers, floats, strings, or maybe something exotic like complete 
symbol tables.  Consequently, you will often see Mythryl code giving the type 
explicitly in such cases:

\begin{verbatim}
    result_list = ([]: List(String));
\end{verbatim}

As a general rule, if the Mythryl compiler cannot deduce the type of a variable, 
the human reader of the code probably cannot either, so such type declarations 
are in any case welcome documention.

The Mythryl compiler constructs a global dependency tree of all api declarations 
and package definitions and then compiles rootward from the leafs.  Consequently, 
when it compiles a package, it has in hand full type information about all other 
modules referenced by that package.  (Also as a consequence, the Mythryl compiler 
gets very upset if you have cyclic dependencies between packages:  It then 
has no idea how to get started compiling.  This is the ``recursive modules'' 
problem, which has received a great deal of attention from researchers.)


\cutend*

% --------------------------------------------------------------------------------
\subsection{Mythryl Types:  Elementary Types and Type Constructors}
\cutdef*{subsubsection}

\begin{quote}\begin{tiny}
       ``Using ``Void'' for a non-empty type is barbaric!''\newline
         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~---Robert Harper, co-author of {\it The Definition of Standard ML}
\end{tiny}\end{quote}

Type systems start with a few irreducible elementary types together 
with some operators which generate new types from previously existing 
ones.  Mythryl's type system is no exception.

Mythryl's core elementary types are:
\begin{itemize}
\item {\bf Void}:  Like C {\bf void}, this is the value returned by a function which returns 
nothing interesting, and the argument value given to a function which really needs 
no argument.  There is exactly one value of this type, which is written {\tt ()}. 
(Theoreticians prefer to call this type {\bf unit}, reserving {\bf void} for the type 
which has no values at all.)
\item {\bf Int}:  The default integer type.  This has 31 bits of precision. (See below.)
\item {\bf Float}:  The default floating point type.  This has 64 bits of precision, and 
thus actually corresponds to C {\bf double}.
\item {\bf Char}:  One seven-bit {\sc ASCII} character.
\end{itemize}

The following core Mythryl vector types are also treated as elementary:
\begin{itemize}
\item {\bf String}:  Logically a vector of Char, but treated as elementary.
\item {\bf Vector}:  Immutable typeagnostic vectors.
\item {\bf Rw\_Vector}:  Mutable typeagnostic vectors.
\end{itemize}

The very special {\bf Exception} sumtype is also predefined.

Mythryl's core mechanisms for constructing new types from old are:

\begin{itemize}
\item The tuple type constructor:  {\tt \verb|New_Type = (Old_Type_A, Old_Type_B, ... );| }
\item The record type constructor:  {\tt \verb|New_Type = { fieldname_a => Old_Type_A, fieldname_b => Old_Type_B, ... );| }
\item The arrow type constructor for functions:  {\tt \verb|New_Type = Argument_Type -> Result_Type;| }
\item The {\bf Ref} type constructor for declaring mutable reference cells:  {\tt \verb|New_Type = Ref( Old_Type );| }
\end{itemize}

Finally, Mythryl's sumtype definition facility effectively 
introduces new programmer-defined types and type constructors.

For example the declaration
\begin{verbatim}
    Color = RED | GREEN | BLUE;
\end{verbatim}

effectively defines a new atomic type {\tt Color} which may be used anywhere an 
existing elementary type like {\tt Int} may be used, and the declaration

\begin{verbatim}
    Tree(X) = EMPTY | NODE { key: Int, value: X, left_kid: Tree(x), right_kid: Tree(X) };
\end{verbatim}

effectively defines a new type constructor {\tt Tree(X)} which accepts an 
existing type and generates a new one.

Several types which in other languages are elementary, are in Mythryl 
simply standard library declarations, at least in principle.

For example the the Boolean type, which is elementary in many 
languages, is in Mythryl defined as
\begin{verbatim}
    Bool = TRUE | FALSE;
\end{verbatim}
in the standard library, at least in principle.  (In practice, 
the compiler uses special hardwired knowledge of {\tt Bool} in 
order to produce better code.)

Similarly, Mythryl lists are in theory simply a type defined 
in the standard library by a statement like
\begin{verbatim}
    List(X) = [] | (X ! List(X));
\end{verbatim}

(In practice, {\tt []} and {\tt ! } are not legal end-user 
syntax --- user-defined constructors must be upper-case 
alphabetic --- and the list construction syntax {\tt [ 12, 13, 14 ]} 
is a completely {\it ad hoc} convenience specially hacked into the Mythryl grammar. 
They say that the difference between theory and practice is that in theory 
they are the same but in practice they are different.)

Complicating the above picture, the messy realities of computer hardware motivate the 
definition of a few additional elementary types.  Integers come in 
signed and unsigned and various lengths, and the Mythryl compiler 
needs to know about them all ahead of time to produce good code, 
so we also have the elementary types 
\begin{itemize}
\item {\bf Int1}:  32-bit signed integers.
\item {\bf Int2}:  64-bit signed integers.
\item {\bf Unt8}:  8-bit unsigned integers.
\item {\bf Unt1}: 32-bit unsigned integers.
\item {\bf Unt2}: 64-bit unsigned integers.
\end{itemize}

Similarly, two additional typelocked vector types are irrelevant 
in principle but in practice essential to achieving good space/time 
efficiency:
\begin{itemize}
\item {\bf Unt8\_Rw\_Vector}:  Mutable vectors of 8-bit unsigned integers.
\item {\bf Float64\_Rw\_Vector}:  Mutable vectors of 64-bit floating point numbers.
\end{itemize}

For those interested, some of the real-world process of defining these 
early types in the Mythryl compiler source code may be found in 
\ahrefloc{src/lib/compiler/front/semantic/symbolmapstack/base-types-and-ops.pkg}{src/lib/compiler/front/semantic/symbolmapstack/base-types-and-ops.pkg};

\cutend*

% --------------------------------------------------------------------------------
\subsection{Mythryl Types:  Generativity}
\cutdef*{subsubsection}

When are two types equal?  Consider these two declarations:

\begin{verbatim}
    Student     = { name: String, address: Int };
    Code_Module = { name: String, address: Int };
\end{verbatim}

Should these be considered two different types, or two names for 
the same type?

Should the compiler let us store values of one type in variables 
declared with the other type?

There are two schools of thought on this subject.  Neither is 
right or wrong;  each has advantages and disadvantages, and 
each has been used successfully in both theory and 
practice.

One school of thought focusses on structure.  If two types have 
the same basic structure, if mathematically there can be no problem 
in using them interchangably, then they are equivalent.

According to this school of thought, the above two types are both 
records, they both have fields of the same name, and those fields 
have the same elementary types.  Substituting a value of one type 
for a value of another type cannot possibly make any mathematical 
difference in the course of the computation.  Therefore, the two 
types are the same, just different names for the same thing.

The other school of thought focusses on names.  The clear intent 
of the coder is that {\tt Student} records represent humans, giving their 
name and room number (or some such), whereas {\tt Code\_Module} 
records represent bits of executable code, giving their declared 
name and their current location in memory.  Treating a room number 
as a memory address cannot possibly give rational results, nor is 
adding the name of a code module to a class enrollment list likely 
to accomplish anything useful.

According to this school of thought, the above two declarations 
were written for entirely different purposes, and the compiler 
should definitely do its best to prevent inadvertent mixing of 
the two types of values.

As a matter of practice, the name-oriented approach to typing has 
tended to dominate in programming languages developed by 
working programmers for industrial use --- languages like C.  It 
is very simple to implement and understand.

The structure-oriented approach, by contrast, has tended to dominate 
in programming languages developed by computer science theoreticians 
for research purposes.  It has very clean mathematical semantics.

The Mythryl type system belongs to the structure-oriented school. 
If it were not, almost none of the machinery we have covered in 
these tutorials would be workable.  For example, almost every call to 
a function implicitly defines an anonymous tuple type.  Lacking 
names, a name-oriented compiler would be unable to decide whether 
that function call made sense from a type point of view.  The 
structure-oriented approach, by contrast, has no problem doing 
type analysis of such masses of anonymous tuple types.

One major exception is that every sumtype declaration creates a 
new type:

\begin{verbatim}
    package a {  Color = RED | GREEN | BLUE; };
    package b {  Color = RED | GREEN | BLUE; };
\end{verbatim}

The two types {\tt a::Color} and {\tt b::Color} are different even 
though their definitions are identical.  If you want them to be 
equal, you should have one package borrow its definition from the other:

\begin{verbatim}
    package a {  Color = RED | GREEN | BLUE; };
    package b {  Color = a::Color; };
\end{verbatim}

Still, that far from exhausts the discussion.

What does one do if one definitely wants to create a new type distinct 
from all others?  What happens when a type is exported but its 
definition is not?  Are two such types exported from different modules 
equivalent or not?

Theoreticians can and do spend entire careers exploring such questions 
and the consequences of different policy choices.  Grab a copy of 
Pierce's {\it Types and Programming Languages} if you're interested. 
Here we are just going to summarize the basics of what Mythryl does 
and how to take advantage of it in practical programming.

First a bit of nomenclature.  A type is {\it opaque} if it is exported 
from a package without exposing its underlying structure.  It is 
{\it transparent} otherwise.  For example:

\begin{verbatim}
    api Silly {
        My_Opaque_Color;
        My_Transparent_Color = RED | GREEN | BLUE;
    };

    package silly: Silly {
        My_Opaque_Color      = RED | GREEN | BLUE;
        My_Transparent_Color = RED | GREEN | BLUE;
    };
\end{verbatim}

Here the colors {\tt My\_Opaque\_Color} and {\tt My\_Transparent\_Color} are 
exactly identical within package {\tt silly}.  But due to package {\tt silly} 
being cast to api {\tt Silly} which hides the definition of {\tt My\_Opaque\_Color}, 
the external world knows exactly what the definition is of {\tt My\_Transparent\_Color}, 
but has absolutely no clue about the definition of {\tt My\_Opaque\_Color}.

The critical Mythryl typing rules are thus three:

\begin{itemize}
\item Every sumtype definition introduces a new type.
\item Every opaque type is different from every other opaque type.
\item Transparent types are equivalent if their definitions are structurally equivalent.
\end{itemize}

One practical consequence of this is that if, as a programmer, you wish 
to create a type which is distinct from all other types in the system, 
the way to do so is to export it as an opaque type from a package.

\cutend*

% --------------------------------------------------------------------------------
\subsection{Mythryl Types:  Type Variables}
\cutdef*{subsubsection}

Suppose we want to write a library function which accepts a tuple of two strings 
and returns a tuple containing those two strings in reverse order:

\begin{verbatim}
    api Swap_Lib { 
        swap_strings: (String, String) -> (String, String);
    };

    package swap_lib: Swap_Lib {
        fun swap_strings (a, b) = (b, a);
    };
\end{verbatim}

After hours of debugging we get it working, and are so excited by the 
new horizons thus opened up that we immediately want the same thing 
for integers:

\begin{verbatim}
    api Swap_Lib { 
        swap_strings: (String, String) -> (String, String);
        swap_ints:    (Int,    Int)    -> (Int,    Int);
    };

    package swap_lib: Swap_Lib {
        fun swap_strings (a, b) = (b, a);
        fun swap_ints    (a, b) = (b, a);
    };
\end{verbatim}

Wow!  How about floats?

\begin{verbatim}
    api Swap_Lib { 
        swap_strings: (String, String) -> (String, String);
        swap_ints:    (Int,    Int)    -> (Int,    Int);
        swap_floats:  (Float,  Float)  -> (Float,  Float);
    };

    package swap_lib: Swap_Lib {
        fun swap_strings (a, b) = (b, a);
        fun swap_ints    (a, b) = (b, a);
        fun swap_floats  (a, b) = (b, a);
    };
\end{verbatim}

This is so much fun!  Let's do {\it all} the types!

Um, wait.  There are an {\it infinite number} of possible types in 
Mythryl.  We could be at this a really, really long time.

Furthermore, the code generated by the Mythryl compiler for each of our 
functions is exactly the same;  it doesn't actually depend on the types 
of the arguments at all.

Why cannot we just write one generic {\tt swap} function and be done with it?

In a language like C, there is no way to do this.  At least, no typesafe 
way:  The C type system is not rich enough to have a representation for 
the {\it any type here} concept.  (Although {\tt void*} works as a 
weak approximation.)

In practice, C programmers at this point would simply bypass the type 
system by casting all arguments to {\tt void} on input and casting them 
back again on output.  In short, by lying to the C compiler because it 
is just too dumb to do the job otherwise.

The Mythryl type system is considerably more subtle.  In Mythryl, we can 
actually do this right:

\begin{verbatim}
    api Swap_Lib { 
        swap: (X, X) -> (X, X);
    };

    package swap_lib: Swap_Lib {
        fun swap (a, b) = (b, a);
    };
\end{verbatim}

Here the X identifiers introduce a match-anything type variable.

Type variables do for type declarations what 
parameter variables do for function declarations: They let us 
talk concretely about arbitrary members drawn from a large 
class of possibilities.  In a declaration like

\begin{verbatim}
    fun double x   = 2.0 * x;
\end{verbatim}

the {\tt x} lets us refer to any possible floating number which may 
become relevant during later processing.  In a declaration like

\begin{verbatim}
    swap: (X, X) -> (X, X);
\end{verbatim}

the X lets us refer to any possible {\it type} which may become 
relevant during later processing.

In Mythryl any identifier consisting of a single uppercase character is 
a type variable:

\begin{verbatim}
    A
    B
    C
    ...
    X
    Y
    Z
\end{verbatim}

For the (rare) cases where more semantic content is desirable, Mythryl 
also supports type variable names beginning with such a lone uppercase 
letter and then followed by an underbar and a lower-case identifier:

\begin{verbatim}
    A_sorted_type
    Z_best_type_available
    ...
\end{verbatim}

Returning to our swap-library example, here is a wet run:

\begin{verbatim}
    linux$ my

    eval:  api Swap_Lib { swap: (X, X) -> (X, X); };
    eval:  package swap_lib: Swap_Lib { fun swap (a, b) = (b, a); };

    eval:  swap_lib::swap( 1, 2 );
    (2, 1)

    eval:  swap_lib::swap( "abc", "def" );
    ("def", "abc")

    eval:  swap_lib::swap( 1.23, 3.21 );
    (3.21, 1.23)
\end{verbatim}

In fact we can do even better and allow swapping 
not just any two-tuple of two values of the same type, 
but any two-tuple whatever:

\begin{verbatim}
    api Swap_Lib { 
        swap: (X, Y) -> (Y, X);
    };

    package swap_lib: Swap_Lib {
        fun swap (a, b) = (b, a);
    };
\end{verbatim}

Here the {\tt X} and {\tt Y} type variables can match different types.

Here is the improved version in action:

\begin{verbatim}
    linux$ my

    eval:  api Swap_Lib { swap: (X, Y) -> (Y, X); };
    eval:  package swap_lib: Swap_Lib { fun swap (a, b) = (b, a); };

    eval:  swap_lib::swap( 1, "one" );
    ("one", 1)

    eval:  swap_lib::swap( 2, ("one", { name => "Johnny", age => 21 } )  );
    (("one", { age=21, name="Johnny" }), 2)
\end{verbatim}

Type variables open up whole new worlds of expressiveness in programming.

There are many, many datastructures in which the code really does not 
care what type is in a given slot.

For example, binary trees usually 
care about the types of node keys, because they have to know how to compare 
them for order, but they usually do not care at all about the types of 
node values, because they just store them on request and then produce them 
upon demand.

In a language like C, binary tree implementations have to specify a 
type for such node values anyhow, greatly reducing code reusability, 
but in Mythryl we can --- and do --- write them in fully general form:

\begin{verbatim}
    Tree(X) = EMPTY
            | NODE { key: Float, value: X, left_kid: Tree, right_kid: Tree };
\end{verbatim}

Here {\tt Tree(X)} is essentially a compile-time type function which 
takes a type as argument and returns a new type as its result.  These 
type functions are usually called {\it type constructors}, often truncated to {\it typ}.

For example, we can now start writing api declarations like

\begin{verbatim}
    sum_integer_valued_tree:  Tree(Int) -> Int;
\end{verbatim}

Here {\tt Tree(Int)} is a new type defined in terms of existing ones.

Sometimes, of course, we may be able to build new datastructures out 
of {\tt Tree(X)} without needing to reduce its generality.  For 
example, maybe we have a type which is allowed to hold any pair of 
trees so long as they are of the same type:

\begin{verbatim}
    Tree_Pair(X) = (Tree(X), Tree(X));
\end{verbatim}

The one real lack of generality in the above {\tt Tree} definition is that 
its key type is hardwired.  If we want a binary tree with integer keys, 
we need to write another declaration.  Ditto if we want  a binary tree with 
string keys.

We cannot abstract away from key type by using a type 
variable because the binary tree implemention actually does care about 
key type; it has to know how to compare keys in order to keep the 
tree sorted.

Thus, in order to write a single generic version of binary tree, we need 
a bigger bat.  That bat is the Mythryl {\it generic package}, which is the subject 
of the next section.


\cutend*

% --------------------------------------------------------------------------------
\subsection{Mythryl Generic Packages}
\cutdef*{subsubsection}

Mythryl generics derive from David MacQueen's 1990 design for an SML {\it module system}. 
This sparked off a research effort which continues to this day.  There is still 
much that we do not understand about such module systems.

One thing that is reasonably clear is that as a result of this 
research, we now for the first time have a solid engineering basis 
for programming in the large.  In some ways these module systems are 
what ``object oriented'' programming should ideally have been but in 
practice could not be because we simply did not know enough back 
in 1967 when OOP originated.

The Mythryl generic package system is best understood as a compile-time 
language in which the types are {\sc API}s, the values are 
packages, and the functions are {\it generics} --- entities which 
take a package as an argument and produce another package as 
result.

The process of applying a generic package to a package to produce another package 
is a lot like macro expansion --- but well-typed macro expansion with 
exquisitely carefully worked out semantics.  (SML is the only programming 
language with a fully defined semantics as well as syntax.  The benchmark 
definition is {\it The Definition of Standard ML (Revised)} by Milner, 
Tofte, Harper and MacQueen.  Mythryl, which is essentially SML with a 
Posix face, inherits that semantic clarity and precision.)

Enough verbiage, let's look at a concrete example.  We will define a 
generic binary tree which can deal with any type of key so long as 
it is sortable and of course with any type of value.

First we need to define concretely the notion of a sortable key. 
For our purpose, it consists of some type together with 
a function which can compare two values of that type and announce whether 
the first is greater, equal or less than the second.

The Mythryl standard library already defines a type {\tt Order} 
which will do nicely.  (Re-use is better than re-invention!)

It is defined in \ahrefloc{src/lib/core/init/order.pkg}{src/lib/core/init/order.pkg} as:

\begin{verbatim}
    Order =  LESS | EQUAL | GREATER;
\end{verbatim}

With that in hand, we can define the key concept so:

\begin{verbatim}
    api Key {

        Key;

        compare:  (Key, Key) -> Order;
    };
\end{verbatim}

This demands some type {\tt Key} and a function {\tt compare} which, 
given two {\tt Key}s, returns one of {\tt LESS}, {\tt EQUAL} or 
{\tt GREATER}.  (Actually, I cheated;  Key is also part of the 
Mythryl standard library, as api \ahrefloc{api:Key}{Key}. Never 
replicate what you can simply steal!)

Now we can define the API for our binary tree implementation:

\begin{verbatim}
    api Binary_Tree {

        exception NOT_FOUND;

        package key: Key;

        Tree(X);              # Tree holding any type of value.

        make_tree:            Void -> Tree(X);

        set_key_value_pair:   (Tree(X), key::Key, X) -> Tree(X);

        get_key_value:        (Tree(X), key::Key) -> X;
    };    
\end{verbatim}

Here:
\begin{itemize}
\item {\tt key} defines the type of keys used by this particular binary tree;
\item X represents the type of values held in a particular tree.  (A don't-care wildcard type variable.)
\item {\tt set\_key\_value\_pair} is a function which accepts a tree, a key and a value and returns the resulting new tree.
\item {\tt get\_key\_value} is a function which accepts a tree and a key and returns the matching value.
\end{itemize}

To keep things simple, this is very much a toy api definition.  (For an industrial-strength 
example of such an api see the \ahrefloc{api:Map}{Map} api in the Mythryl standard library.)

Now for the fun part.  Here is a Mythryl generic package to generate implementations of our 
{\tt Binary\_Tree} api:

\begin{verbatim}
    generic package binary_tree_g (k:  Key):  Binary_Tree where key == k
    {
        package key = k;

        exception NOT_FOUND;

        Tree X
            = EMPTY
            | TREE_NODE { key:       key::Key,
                          value:     X,
                          left_kid:  Tree(X),
                          right_kid: Tree(X)
                        };

        fun make_tree ()
            =
            EMPTY;


        fun set_key_value_pair (EMPTY, key, value)
                =>
                TREE_NODE { key, value, EMPTY, EMPTY };

            set_key_value_pair (TREE_NODE { key=>k, value=>v, left_kid, right_kid }, key, value)
                =>
                case (key::compare(key, k))

                EQUAL   => TREE_NODE { key, value, left_kid, right_kid };

                LESS    => case left_kid
                           EMPTY => TREE_NODE { key=>k, value=>v, left_kid=> TREE_NODE { key, value, EMPTY, EMPTY },       right_kid };
                           _     => TREE_NODE { key=>k, value=>v, left_kid=> set_key_value_pair( left_kid, key, value ), right_kid };
                           esac; 

                GREATER => case right_kid
                           EMPTY => TREE_NODE { key=>k, value=>v, left_kid, right_kid=> TREE_NODE { key, value, EMPTY, EMPTY }      };
                           _     => TREE_NODE { key=>k, value=>v, left_kid, right_kid=> set_key_value_pair( right_kid, key, value ) };
                           esac; 
                esac;
        end;


        fun get_key_value (EMPTY, key)
                =>
                raise exception NOT_FOUND;

            get_key_value (TREE_NODE { key=>k, value, left_kid, right_kid }, key)
                =>
                case (key::compare(key, k))
                EQUAL   => value;
                LESS    => get_key_value(  left_kid, key );
                GREATER => get_key_value( right_kid, key );
                esac;
        end;
    };
\end{verbatim}

Since this tutorial is not about 
\ahref{\binarytrees}{binary trees} per se, we will not discuss 
the binary tree construction and lookup algorithms, which are anyhow very vanilla.

The main thing to note is that the above generic package looks just like a 
vanilla {\tt package} declaration except that it takes a {\tt k: Key} 
package argument on the first line.

(The alert reader will also have noted the {\tt where key == k} modifier 
on the {\tt Binary\_Tree} api reference.  This is necessary to specialized 
the generic package {\tt Binary\_Tree} api definition to the particular key type 
in use.)

Now we may generate specific binary tree implementations by invoking the 
generic package with appropriate key package arguments:

\begin{verbatim}
    package int_key {
        Key = int::Int;
        compare = int::compare;
    };

    package binary_tree_with_int_keys
        =
        binary_tree_g( int_key );
\end{verbatim}

Usually there is no point in actually assigning a name to the 
argument package, so instead we pass an anonymous package 
defined on the spot:

\begin{verbatim}
    package binary_tree_with_int_keys
        =
        binary_tree_g (
            package {
                Key = int::Int;
                compare = int::compare;
            }
        );
\end{verbatim}



Put it all together in a test script and it looks like this:

\begin{verbatim}
    #!/usr/bin/mythryl

    api Binary_Tree {

        exception NOT_FOUND;

        package key: Key;

        Tree(X);      # Tree holding any type of value.

        make_tree:            Void -> Tree(X);

        set_key_value_pair:  (Tree(X), key::Key, X) -> Tree(X);

        get_key_value:        (Tree(X), key::Key) -> X;
    };    

    generic package binary_tree_g (k:  Key):  Binary_Tree where key == k
    {
        package key = k;

        exception NOT_FOUND;

        Tree X
            = EMPTY |
              TREE_NODE {    key:       key::Key,
                             value:       X,
                             left_kid:  Tree(X),
                             right_kid: Tree(X)
                        };

        fun make_tree () =  EMPTY;

        fun set_key_value_pair (EMPTY, key, value)
                =>
                TREE_NODE { key, value, left_kid => EMPTY, right_kid => EMPTY };

            set_key_value_pair (TREE_NODE { key=>k, value=>v, left_kid, right_kid }, key, value)
                =>
                case (key::compare(key, k))

                EQUAL   => TREE_NODE { key, value, left_kid, right_kid };

                LESS    => case left_kid
                           EMPTY => TREE_NODE { key=>k, value=>v, left_kid=> TREE_NODE { key, value, left_kid => EMPTY, right_kid => EMPTY }, right_kid };
                           _     => TREE_NODE { key=>k, value=>v, left_kid=> set_key_value_pair( left_kid, key, value ),                     right_kid };
                           esac; 

                GREATER => case right_kid
                           EMPTY => TREE_NODE { key=>k, value=>v, left_kid, right_kid=> TREE_NODE { key, value, left_kid => EMPTY, right_kid => EMPTY } };
                           _     => TREE_NODE { key=>k, value=>v, left_kid, right_kid=> set_key_value_pair( right_kid, key, value )                    };
                           esac; 
                esac;
        end;

        fun get_key_value (EMPTY, key)
                =>
                raise exception NOT_FOUND;

            get_key_value (TREE_NODE { key=>k, value, left_kid, right_kid }, key)
                =>
                case (key::compare(key, k))
                EQUAL   => value;
                LESS    => get_key_value(  left_kid, key );
                GREATER => get_key_value( right_kid, key );
                esac;
        end;
    };


    # Generate a package implementing
    # binary trees with Int keys:
    #
    package binary_tree_with_int_keys
        =
        binary_tree_g (
            package {
                Key     = int::Int;
                compare = int::compare;
            }
        );

    # Define a shorter synonym for the package name:
    #
    package ti = binary_tree_with_int_keys;



    # Create and exercise a binary tree with
    # Int keys and String vals:

    t = (ti::make_tree ()): ti::Tree(String);

    t = ti::set_key_value_pair( t, 1, "one"   );
    t = ti::set_key_value_pair( t, 2, "two"   );
    t = ti::set_key_value_pair( t, 3, "three" );

    printf "%d -> %s\n" 1 (ti::get_key_value( t, 1 ));
    printf "%d -> %s\n" 2 (ti::get_key_value( t, 2 ));
    printf "%d -> %s\n" 3 (ti::get_key_value( t, 3 ));


    # Create and exercise a binary tree with
    # Int keys and Float vals:


    t = (ti::make_tree ()): ti::Tree(Float);

    t = ti::set_key_value_pair( t, 1, 1.0   );
    t = ti::set_key_value_pair( t, 2, 2.0   );
    t = ti::set_key_value_pair( t, 3, 3.0   );

    printf "%d -> %f\n" 1 (ti::get_key_value( t, 1 ));
    printf "%d -> %f\n" 2 (ti::get_key_value( t, 2 ));
    printf "%d -> %f\n" 3 (ti::get_key_value( t, 3 ));



    # Generate a package implementing
    # binary trees with Int keys:
    #
    package binary_tree_with_string_keys
        =
        binary_tree_g (
            package {
                Key     = string::String;
                compare = string::compare;
            }
        );

    # Define a shorter synonym for the package name:
    #
    package ts = binary_tree_with_string_keys;






    # Create and exercise a binary tree with
    # String keys and Int vals:

    t = (ts::make_tree ()): ts::Tree(Int);

    t = ts::set_key_value_pair( t, "one",   1 );
    t = ts::set_key_value_pair( t, "two",   2 );
    t = ts::set_key_value_pair( t, "three", 3 );

    printf "%s -> %d\n" "one"   (ts::get_key_value( t, "one"   ));
    printf "%s -> %d\n" "two"   (ts::get_key_value( t, "two"   ));
    printf "%s -> %d\n" "three" (ts::get_key_value( t, "three" ));



    # Create and exercise a binary tree with
    # String keys and Float vals:

    t = (ts::make_tree ()): ts::Tree(Float);

    t = ts::set_key_value_pair( t, "one",   1.0 );
    t = ts::set_key_value_pair( t, "two",   2.0 );
    t = ts::set_key_value_pair( t, "three", 3.0 );

    printf "%s -> %f\n" "one"   (ts::get_key_value( t, "one"   ));
    printf "%s -> %f\n" "two"   (ts::get_key_value( t, "two"   ));
    printf "%s -> %f\n" "three" (ts::get_key_value( t, "three" ));
\end{verbatim}

Here is a demo run of the script:

\begin{verbatim}
    linux$ ./my-script
    1 -> one
    2 -> two
    3 -> three
    1 -> 1.000000
    2 -> 2.000000
    3 -> 3.000000
    one -> 1
    two -> 2
    three -> 3
    one -> 1.000000
    two -> 2.000000
    three -> 3.000000
    linux$ ./my-script
\end{verbatim}

So there you have it --- four different tree varieties 
from a single code specification.  (And, obviously, we 
could have generated dozens more with negligible 
additional effort.)

Bottom line:  Mythryl generics provide a powerful programming tool for increasing 
code reusability.

For an industrial-strength version of the above example 
see \ahrefloc{src/lib/src/red-black-map-g.pkg}{src/lib/src/red-black-map-g.pkg}.

\cutend*

% --------------------------------------------------------------------------------
\subsection{Mythryl Types:  Extensible Types}
\cutdef*{subsubsection}

The predefined Mythryl sumtype {\tt Exception} is unique in that it may 
be incrementally extended by defining new constructors for it using 
{\tt exception} declarations.

Vanilla Mythryl sumtype declarations require that all constructors belonging 
to the type be declared up front at the point of sumtype definition;  no later 
extension of the sumtype is allowed.  Normally this is good;  it means that 
when you read a sumtype definition in the code you can be sure that what 
you see is the complete story.

But situations can occasionally arise in industrial-scale Mythryl programming in 
which it is desirable to incrementally extend a sumtype.

Programmers can and do simply use the {\tt Exception} sumtype directly in 
such cases, defining new constructors as needed via {\tt exception} 
declarations.

Sometimes, however, it is better to be a little more typesafe by 
keeping such constructors type-distinct from vanilla {\tt Exception} 
constructors.

Here is a hack to define your own extensible sumtypes separate from 
the standard Mythryl {\tt Exception} sumtype:

\begin{verbatim}
    #!/usr/bin/mythryl

    # Each application of api "Extensible" to
    # package "extensible" generates a new
    # package exporting a new type "Extensible":

    api Extensible {
        Extensible;
        make_new_constructor_deconstructor_pair:
            Null_Or(X)
            ->
            (  (X -> Extensible),
               (Extensible -> Null_Or(X))
            );
    };

    package extensible {

        Extensible = Exception;

        fun make_new_constructor_deconstructor_pair _
            =
            {   exception CONSTRUCTOR(X);

                fun deconstructor (CONSTRUCTOR(y)) => THE y;
                    deconstructor _                => NULL;
                end;

                (CONSTRUCTOR, deconstructor);
            };
    };



    # Define two new extensible types,
    # Extensible1 and Extensible2:
    #
    package extensible1 = extensible: Extensible;
    Extensible1 = extensible1::Extensible;                  # First new extensible type.
    #
    package extensible2 = extensible: Extensible;
    Extensible2 = extensible2::Extensible;                  # Second new extensible type.


    # Define two new constructor/deconstructor pairs
    # for each of our new extensible types:
    #
    my (constructor1a, deconstructor1a) = extensible1::make_new_constructor_deconstructor_pair( NULL: Null_Or(Int)    ); 
    my (constructor1b, deconstructor1b) = extensible1::make_new_constructor_deconstructor_pair( NULL: Null_Or(String) ); 
    #
    my (constructor2a, deconstructor2a) = extensible2::make_new_constructor_deconstructor_pair( NULL: Null_Or(Int)    ); 
    my (constructor2b, deconstructor2b) = extensible2::make_new_constructor_deconstructor_pair( NULL: Null_Or(String) ); 



    # Apply all four of our new constructors:
    #
    wrapped1a = constructor1a(  1112  );
    wrapped1b = constructor1b( "food" );
    #
    wrapped2a = constructor2a(  2111  );
    wrapped2b = constructor2b( "foof" );



    # Apply all four of our new destructors,
    # recovering the wrapped values:
    #
    unwrapped1a = the (deconstructor1a wrapped1a);
    unwrapped1b = the (deconstructor1b wrapped1b);

    unwrapped2a = the (deconstructor2a wrapped2a);
    unwrapped2b = the (deconstructor2b wrapped2b);



    # Display our recovered results
    # to the cheering crowd:
    #
    printf "unwrapped1a == %d\n" unwrapped1a; 
    printf "unwrapped1b == %s\n" unwrapped1b; 
    #
    printf "unwrapped2a == %d\n" unwrapped2a; 
    printf "unwrapped2b == %s\n" unwrapped2b; 
\end{verbatim}

Running this produces:

\begin{verbatim}
    linux$ ./my-script
    unwrapped1a == 1112
    unwrapped1b == food
    unwrapped2a == 2111
    unwrapped2b == foof
\end{verbatim}


This is somewhat clumsy.  Whether that is a bug or a feature depends 
on whether you believe the use of extensible types should be encouraged 
or discouraged.

The above construction also has some technical limitations.

As presented, it does not allow creation of 0-ary constructors.  This 
can be circumvented by (say) adding an extra {\tt 
make\_new\_0ary\_constructor} call.

More importantly, it does not allow creating parameterized extensible 
types.

{\bf Credit:} The above construction is adapted from Bernard Berthomieu's 
March 2000 
\ahref{\ooprogrammingstylesinml}{{\it OO Programming Styles in ML}} paper. 
The core technique has been in general circulation for some time.

For a production example of this technique in action see 
\ahrefloc{src/lib/src/property-list.pkg}{src/lib/src/property-list.pkg}.

\cutend*

% --------------------------------------------------------------------------------
\subsection{Mythryl Types:  Phantom Types}
\cutdef*{subsubsection}

{\it \tiny Material in this tutorial is adapted from 
\ahref{\phantomtypes}{Phantom Types and Subtyping} by Fluet and Pucalla, 2006}

Studies have documented productivity differences of as much as fifty  
to one between programmers doing the same work side by side.  Great 
programmers achieve these sorts of results not by working harder than 
mediocre programmers, but by working smarter.  Why do laboriously by 
hand something which the computer can do more reliably and more quickly?

Mythryl provides ample scope to work smarter instead of harder, for those 
so inclined.  One of the great under-appreciated facilities it offers for 
doing so is its Hindley-Milner typechecker.

This typechecker is based on the {\it unify} operation from logic 
programming made famous by Prolog; it is in essence a poor man's 
theorem prover.  Consequently when writing Mythryl type declarations 
you have at your fingertips much of the power of the power of pure 
Prolog.

By using this power inventively, you can program the Mythryl compiler 
to catch problems automatically at compile time which you might 
otherwise wind up having to track down at run time.

In real-world terms, this can mean the difference between being 
home sound asleep at three AM, or working late in a caffeine stupor 
against a deadline trying to track down "one last bug".  That is 
part of the difference between working smarter and working harder.

The full power of Hindley-Milner type checking has become apparent 
only slowly over time;  we are still discovering new ways of applying 
it to solve real-world programming problems.  You might be the first 
to discover yet another!

Many such techniques are based on {\it phantom types}.

In the C world, types and values correspond in a simple way: Usually 
there is a type every value, and values are created for every type.

Hindley-Milner typechecking opens up a new world of possibilities.

For example, it turns out to be possible to implement (emulate) the 
entire C type system via appropriate Mythryl type declarations.  The 
Mythryl C library interface autogeneration utility {\tt c-glue / 
c-glue-maker}, which is the Mythryl port of Matthias Blume's {\sc 
SML/NJ} {\sc NLFFI} package, does this: You may see part of the code 
in 
\ahrefloc{src/lib/c-glue-lib/c.api}{src/lib/c-glue-lib/c.api}.

When doing such advanced Mythryl type hacking, types are often defined 
with no intent of ever creating any directly corresponding data values. 
Because of the lack of corresponding data values, such types are often 
called {\it phantom types}.

When we define phantom types we are ceasing to think in terms 
of runtime code and instead starting to regard the Mythryl 
type language as a way of programming the Mythryl typechecker to perform 
tasks of interest to us at compile time.  We are programming on a different 
plane.

Suppose we are implementing a weakly typed interpreter vaguely like 
Perl or Python.  We have a {\tt Value} type that the interpreter 
manipulates, which supports integer and boolean values, and operations 
like {\tt print}, {\tt increment} and {\tt not} which may be performed upon 
those values.

Our code might well look something like this:
\begin{verbatim}
    #!/usr/bin/mythryl

    Value = INT( Int ) | BOOL( Bool) ; 

    fun make_int_value  (i): Value = INT(  i );
    fun make_bool_value (b): Value = BOOL( b );

    fun print (v: Value)
        =
        case v
        INT( i) => printf "%d" i;
        BOOL(b) => printf "%B" b;
        esac;
       
    fun increment (v: Value): Value
        =
        case v
        INT( i) => INT( i + 1 );
        BOOL(b) => raise exception FAIL "Cannot increment a Boolean value";
        esac;

    fun not (v: Value): Value
        =
        case v
        INT( i) => raise exception FAIL "Cannot 'not' an Int value";
        BOOL(b) => BOOL( bool::not b );
        esac;

    v  = make_int_value( 12 );
    v' = not( v );
\end{verbatim}

Here we have one function each for creating boolean and integer flavors of 
value, a function which can print both boolean and integer values, a 
function which can increment integer values, and a function which can 
{\tt not} boolean values.

The above code will compile just fine, but at runtime the final line 
will produce a {\tt "Cannot 'not' an Int value"}; runtime error.

This is sub-optimal.  As a matter of design praxis, we would prefer to 
catch such errors at compile time rather than at run time if at all 
practical.  (Suppose the program ran for sixty hours before issuing 
the runtime error and exiting!)

We do not want to just make our integer and boolean values completely 
different types, because we want functions like {\tt print} above to 
operate indifferently upon either.  Yet with them both folded into the 
same type, the typechecker has no way of flagging the above sort of 
coding errors.

Phantom types offer a solution:

\begin{verbatim}
    #!/usr/bin/mythryl

    Value(X) = INT( Int ) | BOOL( Bool) ; 

    fun make_int_value  (i): Value(Int)  = INT(  i );
    fun make_bool_value (b): Value(Bool) = BOOL( b );

    fun print (v: Value(X))
        =
        case v
        INT( i) => printf "%d" i;
        BOOL(b) => printf "%B" b;
        esac;
       
    fun increment (v: Value(Int)): Value(Int)
        =
        case v
        INT( i) => INT( i + 1 );
        BOOL(b) => raise exception FAIL "Cannot increment a Boolean value";
        esac;

    fun not (v: Value(Bool)): Value(Bool)
        =
        case v
        INT( i) => raise exception FAIL "Cannot 'not' an Int value";
        BOOL(b) => BOOL( bool::not b );
        esac;

    v  = make_int_value( 12 );
    v' = not( v );
\end{verbatim}

The above code now gives a type error when it compiles.

The crucial difference is that {\tt Value} now takes a phantom type as argument.

Mythryl does not support subtypes in a true mathematical sense, 
but the {\tt Value} phantom type parameter lets us effectively define 
sub-types {\tt Value(Int)} and {\tt Value(Bool)} of our base 
type {\tt Value(X)}.

This lets us distinguish the return types of {\tt make\_int\_value} 
and {\tt make\_bool\_value} by declaring them as respectively 
{\tt Value(Int)} and {\tt Value(Bool)}.

By defining {\tt print} to take a type of {\tt Value(X)}, we allow it 
to be given arguments of types both {\tt Value(Int)} and {\tt Value(Bool)}.

But by defining {\tt increment} and {\tt not} to accept respectively values of 
type {\tt Value(Int)} and {\tt Value(Bool)}, we prime the type-checker to flag any 
attempt to call either with an inappropriate value.

Note that there is never any data value component corresponding to the phantom 
type parameter;  we added the phantom type without changing the runtime sumtype 
in any way.

Note also that we could use any two types whatever as the 
phantom types in the above example, so long as they were typechecker distinct 
--- so long as they did not {\it unify}.

For example, the following program is exactly equivalent, despite the replacement 
of {\tt Int} and {\tt Bool} by {\tt Vector} and {\tt String} as our phantom 
witness types:

\begin{verbatim}
    #!/usr/bin/mythryl

    Value(X) = INT( Int ) | BOOL( Bool ); 

    fun make_int_value  (i): Value(Vector) = INT(  i );
    fun make_bool_value (b): Value(String) = BOOL( b );

    fun print (v: Value(X))
        =
        case v
        INT( i) => printf "%d" i;
        BOOL(b) => printf "%B" b;
        esac;
       
    fun increment (v: Value(Vector)): Value(Vector)
        =
        case v
        INT( i) => INT( i + 1 );
        BOOL(b) => raise exception FAIL "Cannot increment a Boolean value";
        esac;

    fun not (v: Value(String)): Value(String)
        =
        case v
        INT( i) => raise exception FAIL "Cannot 'not' an Int value";
        BOOL(b) => BOOL( bool::not b );
        esac;

    v  = make_int_value( 12 );
    v' = not( v );
\end{verbatim}

This emphasizes the irrelevance of phantom types to the runtime behavior of 
the program;  they are purely compiletime book-keeping.

To help settle the idea, here is a similar example with another setting, 
this time one involving a TCP/IP network socket library.

Here we assume a fictional underlying {\tt net} package which does 
all the work irrelevant to our example:

\begin{verbatim}
    Socket = UNT( one_word_unt:Unt );

    fun make_udp_socket( address: String ): Socket = {
        net::make_udp_socket address;
    };
    fun make_tcp_socket( address: String ): Socket = {
        net::make_tcp_socket address;
    };

    fun udp_send( socket: Socket,  string: String) = {
        net::udp_send( socket, string );
    }
    fun tcp_send( socket: Socket,  string: String) = {
        net::tcp_send( socket, string );
    }

    fun close_socket( socket: Socket ) = {
        net::close_socket( socket );
    }    
\end{verbatim}

Once again, the issue here is that we have two types, {\tt upd} and {\tt tcp} 
sockets, which are neither completely distinct nor identical.  We can only 
call {\tt udp\_send} on {\tt udp} sockets and only call {\tt tcp\_send} on 
{\tt tcp} sockets, but we may call {\tt close\_socket} on either.  Given the 
above implementation, unfortunately, doing a send on the wrong type socket 
will be detected only at runtime, not at compile type.

Once again, we can solve the problem by adding phantom types to record 
the needed subtyping information.  This time we declare some fresh 
sumtypes to use as the phantom types, just to improve readability:

\begin{verbatim}
    Udp = UDP;          # Used only as phantom type.
    Tcp = TCP;          # Used only as phantom type.

    Socket(X) = UNT( one_word_unt:Unt );

    fun make_udp_socket( address: String ): Socket(UDP) = {
        net::make_udp_socket address;
    };
    fun make_tcp_socket( address: String ): Socket(TCP) = {
        net::make_tcp_socket address;
    };

    fun udp_send( socket: Socket(UDP),  string: String) = {
        net::udp_send( socket, string );
    }
    fun tcp_send( socket: Socket(TCP),  string: String) = {
        net::tcp_send( socket, string );
    }

    fun close_socket( socket: Socket(X) ) = {
        net::close_socket( socket );
    }    
\end{verbatim}

Now any attempt to do a send on the wrong type of socket will 
draw a compile error, but we may still call {\tt close\_socket} on 
either type of socket.

Suppose now that we wanted to encode a two-level type hierarchy using 
phantom types:  We have a value type which subdivides into floating 
point and integer, where the integer type in turn subdivides into 
32-bit and 64-bit integers.  We have a {\tt print\_value} operation 
which may be applied to any of them, an {\tt exp} operation which 
applies only to floats, an {\tt increment} operation which applies 
to both integer types, and a {\tt negate} operation which (for 
some reason) applies only to 32-bit integers.

We can implement this via phantom types by using two phantom type 
type variables in our {\tt Value} definition instead of just one 
as above:

\begin{verbatim}
    #!/usr/bin/mythryl

    My_Int     = MY_INT;
    My_Int1   = MY_INT1;
    My_Int2   = MY_INT2;
    My_Float   = MY_FLOAT;

    Value(X,Y) = INT1(one_word_int::Int) 
               | INT2(two_word_int::Int)
               | FLOAT(float::Float)
               ;

    fun make_int1 (i: one_word_int::Int):           Value(My_Int, My_Int1)
        =
        INT1(i);

    fun make_int2 (i: two_word_int::Int):           Value(My_Int, My_Int2)
        =
        INT2(i);

    fun make_float (f: float::Float):         Value(My_Float, Y)
        =
        FLOAT(f);

    fun print_value( v: Value(X,Y) )
        =
        case  v
        INT1(i) =>   print (one_word_int::to_string i);
        INT2(i) =>   print (two_word_int::to_string i);
        FLOAT(f) =>   print (float::to_string f);
        esac;

    fun increment( v: Value(My_Int,Y) ):      Value(My_Int,Y)
        =
        case  v
        INT1(i) =>   INT1( i + 1 );
        INT2(i) =>   INT2( i + 1 );
        _        =>   raise exception FAIL "increment: impossible case";
        esac;

    fun negate( v: Value(My_Int,My_Int1) ):   Value(My_Int,My_Int1)
        =
        case  v
        INT1(i) =>   INT1( one_word_int::neg i );
        _        =>   raise exception FAIL "negate: impossible case";
        esac;

    fun exp( v: Value(My_Float,Y) ):          Value(My_Float,Y)
        =
        case  v
        FLOAT(f) =>   FLOAT( float::math::exp(f) );
        _        =>   raise exception FAIL "exp: impossible case";
        esac;
\end{verbatim}

Quite general hierarchical subtyping relationships may be encoded and checked 
using phantom types.  In general, for each additional level of hierarchy we 
will add one additional phantom type variable.  For an in-depth discussion see 
\ahref{\phantomtypes}{Phantom Types and Subtyping} by Fluet and Pucalla, 2006, 
from which much of the material in this tutorial was adapted.

\cutend*

% --------------------------------------------------------------------------------
\subsection{Mythryl Packages:  Strong vs Weak}
\cutdef*{subsubsection}

We have 
\ahrefloc{section:tut:delving-deeper:libraries-and-apis}{previously discussed}  
{\it casting} a package to an API so as to achieve implementation hiding by 
removing from view all package elements not declared in the API.

That kind of package casting is usually called {\it strong sealing} in the 
functional programming literature.

Recent research has established there to be a spectrum of plausible and in 
fact useful forms of package casting.  At present Mythryl implements two: 
\begin{itemize}
\item {\bf Strong} package casting.  (The normal case.)
\item {\bf Weak} package casting.
\end{itemize}

Strong package casting verifies that the package declaration is consistent 
with the api declaration --- for example that all required functions are present 
and of the right type --- and then hides from external view all remaining package elements.
Also, types declared as opaque in the api

\begin{verbatim}
    My_Type;
\end{verbatim}

become opaque to the outside world under strong casting.  Under Mythryl typing 
rules, this also makes them new types, different from all previously declared types.

Strong package casting may be included in your original package definition:

\begin{verbatim}
    #!/usr/bin/mythryl

    api My_Api {
        My_Type;
        print_it: My_Type -> Void;
    };

    package my_root_package: My_Api {

        My_Type = String;

        fun private_print_fn  string  =  printf "My_Type value == '%s'\n"  string;
        fun print_it          string  =  private_print_fn  string;
    };
\end{verbatim}

Here we have cast {\tt my\_package} to {\tt My\_Api} in order to hide 
both the structure of {\tt My\_Type} and also the helper function 
{\tt private\_print\_fn}.  The external world sees only an 
opaque type {\tt My\_Type} and a function {\tt print\_it} which operates 
upon that type.  This means that changes in the definition of {\tt My\_Type} 
cannot possibly break external code --- which is what makes such package casting 
so useful in the design and implementation of large software systems.

We can also cast a package after the fact with an API as a separate operation from 
package definition:

\begin{verbatim}
    #!/usr/bin/mythryl

    api My_Api {
        My_Type;
        print_it: My_Type -> Void;
    };

    package my_root_package {

        My_Type = String;

        fun private_print_fn  string  =  printf "My_Type value == '%s'\n"  string;
        fun print_it          string  =  private_print_fn  string;
    };


    package my_cast_package
        =
        my_root_package: My_Api;
\end{verbatim}

This may seem uselessly obtuse at first blush:  Why not just do the 
package casting up front and be done with it?  But consider this example:

\begin{verbatim}
    #!/usr/bin/mythryl

    api My_First_Api {
        My_Type;
        print_it:   My_Type -> Void;
    };

    api My_Second_Api {
        My_Type;
        print_fn:   My_Type -> Void;
    };

    package my_root_package {

        My_Type = THIS( String )
                | THAT( Int )
                ; 

        fun private_print_fn  string  =  printf "My_Type value == '%s'\n"  string;
        fun print_it          string  =  private_print_fn  string;
        fun print_fn          string  =  private_print_fn  string;
    };


    package my_first_package  =   my_root_package:  My_First_Api;
    package my_second_package =   my_root_package:  My_Second_Api;
\end{verbatim}

Here we have generated two different externally visible packages from 
a single root package definition by casting it to two different api 
definitions.  In a small tutorial example this looks silly, but this 
can become a real asset in the context of a large software development 
project where apis are defined and implemented by multiple groups and 
a given module may need to implement multiple externally provided 
apis.

Now we can begin to understand why the modern {\it package casting} approach is 
more powerful than the older technique of scattering {\tt public} and 
{\tt private} keywords all through the package definition:  Aside from 
achieving better separation of concerns by divorcing package definition 
from API definition, the {\it package casting} approach defines a {\it package 
algebra} in which package definitions provide the seed values and 
API definitions provide the functions which produce new values from old.

Package casting literally gives us an entirely new language for programming 
in the large.


{\bf Weak} package casting is an older form of package casting which allows 
as much as possible of the original type equality information to 
propagate through to the resulting package interface.  This form was 
developed first and is at this point present for primarily historical reasons.

We designate weak package casting by adding a {\tt (weak)} qualifier after the 
casting colon:

\begin{verbatim}
    #!/usr/bin/mythryl

    api My_Api {
        My_Type;
        print_it: My_Type -> Void;
    };

    package my_package: (weak)  My_Api {

        My_Type = String;

        fun private_print_fn  string  =  printf "My_Type value == '%s'\n"  string;
        fun print_it          string  =  private_print_fn  string;
    };
\end{verbatim}
 
This version leaves visible the maximal possible amount of equality 
information about {\tt My\_Type}, allowing it to still be externally 
equal to type {\tt String}, while still protecting the internal {\tt 
private\_print\_fn} function frome external access.

Sometimes this additional propagation of type equality information 
is just what you need.  Strong package casting is the default and 
normal case, but having both strong and weak package casting 
available makes Mythryl more expressive for programming in the large.

\cutend*

% --------------------------------------------------------------------------------
\subsection{Package and API Subclassing}
\cutdef*{subsubsection}

We have \ahrefloc{section:tut:bare-essentials:packages}{seen} that 
the Mythryl {\tt include} statement may be used to dump package 
definitions into the current namespace in order to save us the 
effort of writing explicit package qualifiers:

\begin{verbatim}
    linux$ my

    eval:  v = vector::from_list [ 1, 2, 3 ];
    #[1, 2, 3]

    eval:  include vector;

    including vector
      Vector  X = Vector(X);
          max_len : Int;
          from_list : List(X) -> Vector(X);
          tabulate : (Int, (Int -> X)) -> Vector(X);
          length : Vector(X) -> Int;
          get : (Vector(X), Int) -> X;
          _[] : (Vector(X), Int) -> X;
          set : (Vector(X), Int, X) -> Vector(X);
          cat : List(Vector(X)) -> Vector(X);
          keyed_apply : ((Int, X) -> Void) -> Vector(X) -> Void;
          apply : (X -> Void) -> Vector(X) -> Void;
          keyed_map : ((Int, X) -> Y) -> Vector(X) -> Vector(Y);
          map : (X -> Y) -> Vector(X) -> Vector(Y);
          keyed_fold_forward : ((Int, X, Y) -> Y) -> Y -> Vector(X) -> Y;
          keyed_fold_backward : ((Int, X, Y) -> Y) -> Y -> Vector(X) -> Y;
          fold_forward : ((X, Y) -> Y) -> Y -> Vector(X) -> Y;
          fold_backward : ((X, Y) -> Y) -> Y -> Vector(X) -> Y;
          keyed_find : ((Int, X) -> Bool)
                  -> Vector(X) -> Null_Or(((Int, X)));
          find : (X -> Bool) -> Vector(X) -> Null_Or(X);
          exists : (X -> Bool) -> Vector(X) -> Bool;
          all : (X -> Bool) -> Vector(X) -> Bool;
          compare_sequences : ((X, X) -> Order) -> (Vector(X), Vector(X)) -> Order;

    eval:  v = from_list [ 3, 4, 5 ];
    #[3, 4, 5]
\end{verbatim}

The {\tt include} statement is also often used to dump the contents of 
one package definition into another, with the idea of defining the second 
package just by overriding a few definitions:

\begin{verbatim}
    #!/usr/bin/mythryl

    api Chitchat {
        say_hello:    String -> Void;
        say_goodbye:  String -> Void;
    };

    package p1: Chitchat {

        fun say_hello   string =  printf "Hi %s!\n"      string;
        fun say_goodbye string =  printf "Goodbye %s!\n" string;
    };

    package p2: Chitchat {

        include p1;

        fun say_hello   string =  printf "Well hello there, %s."  string;
    };
\end{verbatim}

Here we have dumped both function definitions from package {\tt p1} 
into {\tt p2} and then overriden just the definition of interest.

This can be a very economical mode of programming in a production setting 
where package {\tt p1} may be very large and the changes to be made very 
small.

The same technique may be used to define a new API in terms of additions 
or changes to an existing one.  Here we define an extended api and then 
a matching extended package:

\begin{verbatim}
    #!/usr/bin/mythryl

    api Chitchat {
        say_hello:    String -> Void;
        say_goodbye:  String -> Void;
    };

    api Chitchattier {

        include Chitchat;

        say_little:   String -> Void;
    };

    package p1: Chitchat {

        fun say_hello   string =  printf "Hi %s!\n"      string;
        fun say_goodbye string =  printf "Goodbye %s!\n" string;
    };

    package p2: Chitchattier {

        include p1;

        fun say_little  string =  printf "Hot enough for you, %s?"  string;
    };
\end{verbatim}

This can be a very useful technique on large software projects.

\cutend*

% --------------------------------------------------------------------------------
\subsection{Call/CC and Soft Thread Programming}
\cutdef*{subsubsection}
\label{section:tut:full-monte:callcc}

The fundamental concurrent programming primitive in modern praxis 
is {\tt callcc}, "call with current fate", which may be 
thought of as saving the current call stack.

(Mythryl actually uses a stackless implementation, so in a literal 
sense there is no call stack to save or restore.  This makes the 
Mythryl {\tt callcc} implementation perhaps a hundred times faster 
than the typical competing implementation; in Mythryl {\tt callcc} 
takes essentially the same time as any other function call, and 
works much the same way.)

Mythryl's version of this facility pairs it with 
{\tt throw}, which may be thought of as resuming a saved call stack.

The {\tt callcc} interface represents low-level functionality 
reaching deep into system internals;  the application level 
interface to it is defined in \ahrefloc{src/lib/std/src/nj/fate.api}{src/lib/std/src/nj/fate.api} 
and \ahrefloc{src/lib/std/src/nj/fate.pkg}{src/lib/std/src/nj/fate.pkg}.

The core of the API is

\begin{verbatim}
    Fate(X);

    callcc:  (Fate(X) -> X) -> X;
    throw:    Fate(X) -> X -> Y;
\end{verbatim}

where

\begin{itemize}
\item {\tt Fate(X)} is the type of fates taking arguments of type X.
\item {\tt callcc user\_function} passes the current fate {\tt k} to {\tt userfunction}.
      Later doing {\tt throw cc x} effectively results in the original 
      {\tt callcc user\_function} returning {\tt x}.
\item {\tt throw k x} resumes fate {\tt k} (obtained from {\tt callcc}) with argument {\tt x}.
\end{itemize}

The {\tt callcc} facility is really only useful in applications large enough 
to need multiple logical threads of control;  consequently, simple examples 
tend to look fairly silly.  Here is a minimal example of using {\tt callcc} and {\tt throw}:

\begin{verbatim}
    #!/usr/bin/mythryl

    callcc = fate::callcc;
    throw  = fate::throw;

    fun test_callcc string
        =
        callcc( fn current_fate =  throw  current_fate  string );

    printf "Test result is '%s'.\n"  (test_callcc "foo");
\end{verbatim}

As you probably suspect, when run this yields:

\begin{verbatim}
    linux$ ./my-script
    Test result is 'foo'.
\end{verbatim}

Here we first use {\tt callcc} to get access to the {\tt current\_fate} 
and then immediately use {\tt throw} to resume that fate.

In a more realistic example we would be doing something like maintaining 
a priority queue of fates, entering {\tt current\_fate} into 
that priority queue, extracting the next fate to run from that 
priority queue, and then using {\tt throw} to transfer control to that 
next fate, thus effecting a "cooperative multitasking" style 
time-slice  context switch;  instead of {\tt test\_callcc} our function 
might be called something like {\tt yield}.

A production example of such coding may be found in 
\ahrefloc{src/app/makelib/concurrency/makelib-thread-boss.pkg}{src/app/makelib/concurrency/makelib-thread-boss.pkg}.

Serious concurrent programming requires an infrastructure of appropriate 
priority queues, locks, message channels and so forth.  The {\it de facto} 
standard concurrent programming solution for the SML world is John H Reppy's 
{\tt CML}, documented in his book {\it Concurrent Programming in ML}.  This 
package has been partially ported to Mythryl;  the source code compiles and is in the 
tree rooted at {\tt src/lib/thread-kit}.  A suitable entrypoint for reading 
purposes is \ahrefloc{src/lib/src/lib/thread-kit/src/core-thread-kit/threadkit.api}{src/lib/src/lib/thread-kit/src/core-thread-kit/threadkit.api}.

The {\tt thread-kit} code is not currently operational or supported;  the change of syntax 
from SML to Mythryl has introduced some superficial breakage which I have 
not yet had time to pin down and fix.


\cutend*

% --------------------------------------------------------------------------------
\subsection{Library Freezing}
\cutdef*{subsubsection}
\label{section:tut:full-monte:library-freezing}

We have \ahrefloc{section:tut:delving-deeper:compiling-a-stand-alone-executable}{seen} 
how to define a Mythryl library and compile it using Mythryl's {\tt make} function.

Using this approach, each time the {\tt make} command is issued, all source files 
contributing to the library are checked and their last-modified times compared with 
the last-modified time of the library proper;  if the compiled library code is 
out of date, the logically minimum amount of recompilation needed is done to 
reconstruct it.

This is exactly the behavior one wants during development, but scanning the source 
files does take time, and for production deployment of a library, say on an 
embedded Linux box with limited memory, one may not even want to have the source 
code around.

Mythryl supplies the {\tt freeze} function for such production deployment. 
{\it Freezing} a library compiles it into a binary {\it freezefile} form in which the source 
code is no longer needed.  When the Mythryl {\tt make} command sees such a 
freezefile, it does not even look for the library sourcefiles, or even the 
library {\tt .lib} file.

Continuing the previous example, here is how we would construct a freezefile 
for it:

\begin{verbatim}
    linux$ my

    eval:  make "factor.lib";
        src/app/makelib/main/makelib-g.pkg:   Running   .lib file    factor.lib
          parse/libfile-parser-g.pkg:   Reading   make   file   factor.lib                                            on behalf of <toplevel>
makelib/compilable/thawedlib-tome.pkg:   Parsing   source file   factor.api
makelib/compilable/thawedlib-tome.pkg:   Parsing   source file   factor.pkg
makelib/compilable/thawedlib-tome.pkg:   Parsing   source file   main.pkg
    .../compile/compile-in-dependency-order-g.pkg:   Compiling source file   factor.api                                              to object file   factor.api.compiled
    .../compile/compile-in-dependency-order-g.pkg:   Compiling source file   factor.pkg                                              to object file   factor.pkg.compiled
    .../compile/compile-in-dependency-order-g.pkg:   Compiling source file   main.pkg                                                to object file   main.pkg.compiled
        src/app/makelib/main/makelib-g.pkg:   New names added.

    eval:  freeze "factor.lib";
        src/app/makelib/main/makelib-g.pkg:   Running   .lib file    factor.lib
          parse/libfile-parser-g.pkg:   Reading   make   file   factor.lib                                            on behalf of <toplevel>
    .../compile/compile-in-dependency-order-g.pkg:   Loading                 factor.api
    .../compile/compile-in-dependency-order-g.pkg:   Loading                 factor.pkg
    .../compile/compile-in-dependency-order-g.pkg:   Loading                 main.pkg

       .../freezefile/freezefile-g.pkg:   Creating  library       factor.lib.frozen


    eval:  ^D

    linux$ ls -l
    -rw-r--r-- 1 cynbe cynbe    48 2009-03-09 02:19 factor.api
    -rw-r--r-- 1 cynbe cynbe   283 2009-03-09 02:19 factor.api.compiled
    -rw-r--r-- 1 cynbe cynbe   172 2009-03-09 02:28 factor.lib
    -rw-r--r-- 1 cynbe cynbe  5409 2009-03-12 13:57 factor.lib.frozen
    -rw-r--r-- 1 cynbe cynbe   488 2009-03-09 02:18 factor.pkg
    -rw-r--r-- 1 cynbe cynbe  1107 2009-03-09 02:18 factor.pkg.compiled
    -rw-r--r-- 1 cynbe cynbe  1161 2009-03-09 02:34 main.pkg
    -rw-r--r-- 1 cynbe cynbe  3391 2009-03-09 02:34 main.pkg.compiled
\end{verbatim}

Here the new {\tt factor.lib.frozen} library archive file logically 
replaces all the other files shown, including the four {\tt .compiled} 
object code files, the {\tt .api} and {\tt .pkg} source files and 
the master {\tt factor.lib} library definition file.  All of 
these files may now be removed if desired.

To load the freezefile into Mythryl you still do {\tt make "factor.lib"} 
but as long as {\tt factor.lib.frozen} exists, {\it makelib} does not even 
look for the {\tt factor.lib} file.

(Of course, as often as not, the factor library is listed as needed by 
some other {\tt .lib} file and is pulled in automatically as part of 
the {\tt make} without explicit mention on your part.)

To unfreeze the library, just remove the {\tt factor.lib.frozen} file. 
Mythryl's {\tt make} will then revert to its usual behavior of checking 
all sourcefile timestamps and automatically recompiling as needed.


\cutend*

% --------------------------------------------------------------------------------
\subsection{Overloaded Operators}
\cutdef*{subsubsection}

The alert reader may have noticed that the Mythryl arithmetic operators such as 
{\tt +} and {\tt *} are anomalous in that they can operate upon both integer 
and floating point numbers.

This is indeed an anomaly.

Such symbols are termed {\it overloaded}.  They actually refer ambiguously 
to {\it several} underlying symbol definitions.

Such overloading works quite naturally in languages like {\tt C++} where 
every identifier is explicitly assigned a type by the programmer  
when it enters scope.

Such overloading does not sit very well with Mythryl type inference, alas. 
Mythryl type inference works by propagating 
type information out from symbols with known type through the rest of the 
program syntax tree.  Symbols which may refer to any one of several underlying 
definitions and thus potentially have any one of several types add unwelcome 
complexity and opacity to the type inference computation.

This is why (for example) the closely related 
\ahref{\ocaml}{Ocaml} programming language abjures overloading completely. 
The price it pays for this is having to use different symbols for integer 
and floating point multiplcation --- {\tt *} vs {\tt *.} --- which some people consider 
ugly. It gets uglier if one wants to add such support for other types 
such as complex numbers, vectors and matrices.

Consequently Mythryl has elected to support operator overloading, albeit 
without great enthusiasm or conviction.  You might think of operator 
overloading as the {\tt goto} of the Mythryl type and syntax system, 
somewhat sinister and unwelcome, and by preference not mentioned or used, 
but occasionally just exactly the right tool for the job.

Important note:  The Mythryl compiler resolves overloaded operators at compiletime; 
any given reference in source code to an overloaded operator 
must resolve at compiletime to exactly one of the underlying possibilities. 
This means that one {\it cannot} use overloaded operators to write a function 
which will operate on different types at different times, for example a 
function which does integer additions when handed integers and float 
additions when handed floats.  

You can find the Mythryl standard library's set of default operator 
overloading declarations in the aptly named 
\ahrefloc{src/lib/core/init/pervasive.pkg}{src/lib/core/init/pervasive.pkg} 
package.  A typical sample looks like:

\begin{verbatim}
    overloaded my + :   ((X, X) -> X)
        =
        ( tagged_int::(+),
          one_word_int::(+),
          two_word_int::(+),
          intgr::(+),
          tagged_unt::(+),
          strcat,
          one_word_unt::(+),
          two_word_unt::(+),
          flt64::(+),
          unt08plus
        );
\end{verbatim}

This declares that the overloaded {\tt +} binary operator combines two values to 
produce a third, all of the same type, and that it may be used to ambiguously 
refer to any of the corresponding underlying addition symbols from any of the indicated 
arithmetic-type packages --- and to strings too, just for good measure. 

You might use the following syntax to add support for complex, 
quaternion, oction and matrix addition to the pre-existing overloaded 
addition operation:

\begin{verbatim}
    overloaded my + :   ((X, X) -> X)
       +=
        ( complex::(+),
          quaternion::(+),
          oction::(+),
          matrix::(+)
        );
\end{verbatim}

Here the substitution of {\tt +=} for {\tt =} signals 
the compiler that the pre-existing overloaded operator definition 
should be extended rather than overridden.

\cutend*

% --------------------------------------------------------------------------------
\subsection{Experimental Object Oriented Programming Support}
\cutdef*{subsubsection}
\label{section:tut:full-monte:experimental-object-oriented-programming-support}

{\bf Background}

Object oriented programming ("oop") in ML family languages has a long and vexed history.

Authorities as eminent as Robert Harper, co-author of {\it The Definition of Standard ML} 
have concluded that SML is better off without oop.  The standard SML programming style 
solves problems in a quite different style which works just fine;  trying to mix oop and 
ML is like trying to mix oil and water.

On the other hand eminent researcher Xavier Leroy has successfully implemented a flavor 
of oop in Ocaml and reports that it yields significant benefits in parts of the OCaml 
compiler implementation.  Ocaml users use oop in only about ten percent of their programs, 
however;  most of the time they seem content to stick to traditional ML programming style. 

Similarly, eminent SML researcher John H Reppy has collaborated with Kathleen Fisher on 
the experimental language \ahref{\moby}{Moby} which combines ML, oop and concurrent 
programming support.

Much of the design problem revolves around how to reconcile oop semantics with the 
ML type system.  Subclassing is difficult to describe in type terms without subtyping, 
but adding subtypes to the ML type system is a major increment in complexity which can 
easily push the type deduction problem over the undecidability cliff.

This release of Mythryl contains a first-cut implementation of the 
approach to oop in ML outlined by Bernard Berthomieu in his March 2000 
paper \ahref{\ooprogrammingstylesinml}{OO Programming Styles in ML}. 
The focus of this paper is upon supporting oop without changes to the 
type system or core language; in principle, all the techniques he 
describes can be coded up by hand without any changes to the compiler 
at all.  This provides complete confidence that no violence is being 
done to the core semantics of the language.  The resulting code is 
however quite unwieldy; compiler support to autogenerate most of the 
code can reduce by 90% the amount of code which must be written by the 
application programming.

Berthomieu's core idea is to express objects as tuples with one unspecified 
component which may be filled in by subclasses.

For example, we might have an object with state

\begin{verbatim}
    Self(X) = (Int, String, Float, X);
\end{verbatim}

where the {\tt Int}, {\tt String} and {\tt Float} components are the local 
state and the wildcard {\tt X} component can be defined by subclasses any way they 
please.  The subclasses will in turn provide a {\tt Y} component for their 
subclasses to define, and so forth.  The state for a given object then 
becomes a chain of tuples with one link for the class plus one for each 
of its superclasses.

Methods for a given class may then be written to take arguments of type 
{\tt Self(X)}, taking advantage of Mythryl's don't-care parametric polymorphism 
to operate equally well on instances of the class itself or of any subclass 
of it; state components belonging to subclasses are simply ignored.

This idea becomes fairly complicated by the time it is worked out in 
detail while providing implementation hiding, late binding, method 
overriding and so forth;  I refer the really interested reader to Berthomieu's 
paper, and turn instead to the user's eye view of the current Mythryl implementation 
which is based upon his "simple dispatch with embedded methods" approach, section 
4.2 and appendix A2.3.2.

A Mythryl class is a Mythryl package with special sauce;  all regular package 
functionality is supported, plus additional constructs specific to object-oriented 
programming.  Internally the compiler converts a class into a standard package during 
typechecking; the rest of the compiler knows nothing about oop.

{\bf A simple stand-alone counter class}

Let us start by re-implementing the simple counter class from the 
\ahrefloc{section:tut:delving-deeper:roll-your-own-oop}{"roll your own oop" tutorial}:

\begin{verbatim}
    #!/usr/bin/mythryl

    class counter {

        # Declare our object's state field,
        # an integer counter:
        # 
        field my  Ref(Int)  counter = REF 0;

        # Define a message which returns the
        # value of our object's counter:
        #
        message fun    Self(X) -> Int
            get self
                =
                *(self->counter);

        # Define a message which increments the
        # value of our object's counter:
        #
        message fun    Self(X) -> Void
            increment self
                =
                self->counter := *(self->counter) + 1;

        # Define a message which resets the
        # value of our object's counter:
        #
        message fun    Self(X) -> Void
            reset self
                =
                self->counter := 0;


        # Define a nice function for creating instances
        # of this class.  The make__object() function
        # is autosynthesized by the compiler:
        #
        fun new ()
            =
            make__object ((), ());
    };


    # Demonstration of counter use:
    print "\n";

    include counter;

    counter = new ();      printf "State of counter after creation  d=%d\n" (get counter);
    increment counter;     printf "State of counter after increment d=%d\n" (get counter);
    reset counter;         printf "State of counter after reset     d=%d\n" (get counter);
\end{verbatim}

When run this will produce as before

\begin{verbatim}
    linux$ ./my-script

    State of counter after creation  d=0
    State of counter after increment d=1
    State of counter after reset     d=0
\end{verbatim}

Points to note:

\begin{itemize}

\item Declaration of types is mandatory for both fields and messages. 
      The general type deduction problem is undecidable otherwise. It 
      is good documentation anyhow.

\item Except for the {\tt message} qualifier and the required type 
      declaration, message functions are declared using the same syntax 
      as any other Mythryl function.

\item The message recipient (first argument of a message function) 
      must be declared as having type {\tt Self(X)}.  The corresponding 
      parameter is usually named {\tt self}, but this is pure convention; 
      you may name it anything you like.

\item Object fields are accessed using {\tt self->field} syntax.  Do not 
      put whitespace around the {\tt -> }.

\item Messages are implemented as functions which look entirely vanilla 
      to the outside world;  they may be used exactly as any other function. 
      Internally, they dynamically look up and invoke a method function 
      stored in the message recipient's method record.  This is very 
      similar to what is done by most modern oop languages.

\end{itemize}

I do not suggest that you try understanding the following in detail 
(although you might find it an interesting and educational exercise), 
but just to give you some rough idea of what (and how much!) code 
the compiler is synthesizing for you, here is approximately what 
the above turns into after the oop constructs have been re-expressed 
in vanilla Mythryl.  I have added explanatory comments.  Note that 
synthesized identifiers by convention incorporate a double underline 
to reduce risk of unexpected interactions with user-defined identifiers.

NB: The following code depends on support code from 
\ahrefloc{src/lib/src/object.pkg}{src/lib/src/object.pkg} and 
\ahrefloc{src/lib/src/oop.pkg}{src/lib/src/oop.pkg}.

\begin{verbatim}

    # class 'counter' expands into package 'counter':
    #
    package counter {

        package dummy__oop__ref = oop;          # Force support library 'oop' to load.
        package dummy__object_ref = object;     # Force support class 'object' to load.

        package super = object;


        # Berthomieu's approach requires that
        # type Full__State(X) be opaque, so
        # we declare it in an internal package
        # which we can strong-seal with an
        # appropriate api (thus making Full__State(X)
        # opaque) and then 'include' back into the
        # main package.  This is a useful general trick:
        #
        package oop__internal
            :  
            api {

                # The full state record for a class consists of
                # its own local state plus a slot of type X for
                # whatever state a subclass of us might want.
                # Here in the API we declare it as an opaque
                # type, which gives us implementation hiding
                # as well as the type abstraction we need to
                # make object typing work properly:
                #
                Full__State(X);

                # The formal type for instances of this class
                # consists of the type for instances of our
                # superclass (which in this case defaults to
                # 'object' since we did not specify one explicitly)
                # with our Full__State(X) record plugged into its
                # subclass slot:
                # 
                Self(X) =  object::Self(Full__State(X));

                # Myself is Self(X) where X has been resolved to
                # a null pointer (no subclass state).  This is used
                # only when someone creates an instance of this
                # class specifically (as opposed to any subclass):
                #
                Myself =  Self(oop::Oop_Null);

                # Our local object state is split between two records,
                # one holding our fields and one holding our methods:
                #
                Object__Fields(X)  =  { counter: Ref(Int) };
                Object__Methods(X) =  { get:       Self(X) -> Int,
                                        increment: Self(X) -> Void, 
                                        reset:     Self(X) -> Void
                                      };

                # For class 'counter' we specified only one field,
                # with a fixed identifier, but in general we may
                # have multiple fields, some of which are initialized
                # to values supplied to 'make__object' rather than
                # specified in the field declaration.  This record
                # defines one entry for each field whose declaration
                # lacks an initializer:
                #
                Initializer__Fields(X) =  { };

                # Now we declare our three message functions:
                #
                get:         Self(X) -> Int; 
                increment:   Self(X) -> Void; 
                reset:       Self(X) -> Void; 

                # pack__object is the general routine for
                # creating an instance of this class, also
                # called by subclasses to create our part
                # of their state:
                # 
                pack__object:   (Initializer__Fields(X), Void) -> X -> Self(X); 

                # make__object is the general routine for
                # creating an instance of this class specifically.
                # it just calls pack__object, specifying a null
                # subclass state:
                #
                make__object:   (Initializer__Fields(X), Void) -> Myself; 

                # unpack__object is the general routine which our
                # subclasses call to get access to their local state:
                #
                unpack__object:   Self(X) -> (X -> Self(X), X); 

                # get__substate is a streamlined version of unpack__object
                # for use when the ability to recompose the object is not
                # needed:
                #
                get__substate:   Self(X) -> X; 

                # get__fields is a local function for
                # getting access to our own field record.
                # It calls super::get__substate():
                #
                get__fields:   Self(X) -> Object__Fields(X); 

                # get__fields is a local function for
                # getting access to our own methods record.
                # It calls super::get__substate():
                #
                get__methods:   Self(X) -> Object__Methods(X); 

                # make_object__fields combines initialization
                # information from declared field initializers
                # and those supplied via make__object to produce
                # a full fields record for a new object:
                # 
                make_object__fields:   Initializer__Fields(X) -> Object__Fields(X); 

                # For each message defined by the user, we
                # define an override function used to specify
                # a replacement method function implementing it:
                #
                override__get:         ((Self(X) -> Int ) -> Self(X) -> Int ) -> Self(X) -> Self(X);
                override__increment:   ((Self(X) -> Void) -> Self(X) -> Void) -> Self(X) -> Self(X);
                override__reset:       ((Self(X) -> Void) -> Self(X) -> Void) -> Self(X) -> Self(X);
            }
            =
            package {

                # Our local object state consists of a pair of records,
                # one for fields, one for methods.  Its type is mutually
                # recursive with that of our other major types:
                #
                Object__State(X)
                    =
                    OBJECT__STATE { object__fields:  Object__Fields(X), 
                                    object__methods: Object__Methods(X)
                                  }
                    withtype Full__State(X) = (Object__State(X), X)
                    also     Self(X) = super::Self(Full__State(X))
                    also     Myself = Self(oop::Oop_Null)
                    also     Object__Methods(X) = { get:       Self(X) -> Int,
                                                    increment: Self(X) -> Void, 
                                                    reset:     Self(X) -> Void
                                                  }
                    also     Object__Fields(X) = { counter: Ref(Int) }
                    also     Initializer__Fields(X) = { };

                # Convenience function to access our fields record:
                #
                fun get__fields (self: Self(X))
                    =
                    {   my (OBJECT__STATE { object__methods, object__fields }, substate)
                            =
                            super::get__substate  self;

                        object__fields;
                     };

                # Convenience function to access our methods record:
                #
                fun get__methods (self: Self(X))
                    =
                    {   my (OBJECT__STATE { object__methods, object__fields }, substate)
                            =
                            super::get__substate  self;

                        object__methods;
                     };

                # We can't make make__object mutually recursive
                # with our method functions because Mythryl doesn't
                # generalize mutually recursive functions, and it
                # is essential that our message and method functions
                # be generalized, and make__object has to be defined
                # after them in order to have them in scope for building
                # the object__methods record, so we have a little hack
                # where we backpatch a pointer to make__object into a
                # reference which is in-scope to the method functions:
                #
                make__object__ref = REF NULL: Ref(Null_Or(((Initializer__Fields(X), Void) -> Myself)));
                fun make__object arg = (the *make__object__ref) arg;

                # Next come the actual method functions supplied by the user:
                # 
                fun get self
                    =
                    *(.counter (get__fields self));

                fun increment self
                    =
                    (.counter (get__fields self))
                        :=
                        *(.counter (get__fields self)) + 1;

                fun reset self
                    =
                    .counter (get__fields self) := 0;

                # With the methods defined, we can now
                # set up our object__methods record:
                #
                object__methods = { get, increment, reset };

                # Next come the synthesized message functions which
                # look up and invoke the method functions via the
                # object__methods record stored in the recipient
                # object.  The fact that all Mythryl functions
                # logically take exactly one argument and return
                # exactly one result makes life easy for us here:
                #
                fun get (self: Self(X))
                    =
                    {    object__methods = get__methods self;
                         object__methods.get self;
                    };
                fun increment (self: Self(X))
                    =
                    {    object__methods = get__methods self;
                         object__methods.increment self;
                    };
                fun reset (self: Self(X))
                    =
                    {    object__methods = get__methods self;
                         object__methods.reset self;
                    };

                # The synthesized function which constructs
                # the object__fields record for a new object:
                #
                fun make_object__fields (init: Initializer__Fields(X))
                    =
                    { counter => REF 0 };

                # Next the synthesized function to create our
                # portion of a new object.  We use this locally
                # and it also gets invoked by our subclasses:
                #
                fun pack__object (fields_1, fields_0) substate
                    =
                    {   object__fields
                             =
                             make_object__fields  fields_1;

                        self = (super::pack__object ())
                                 ( OBJECT__STATE { object__fields, object__methods },
                                   substate
                                 );
                        self;
                    };

                # Now the function to create an instance specifically
                # of our own class, not of any subclass.  This is just
                # pack__object with a null subclass state:
                #
                fun make__object fields_tuple
                    =
                    pack__object fields_tuple oop::OOP_NULL;

                # Backpatch the above-mentioned reference so that
                # method functions can call make__object:
                #
                                                        my _ =
                make__object__ref
                    :=
                    THE make__object;

                # This function lets our subclass decompose us in a
                # way which allows later recomposition with changes.
                #
                # All the work is done by a helper function from
                # package 'oop':
                #
                fun unpack__object me
                    =
                    oop::unpack_object  (super::unpack__object  me);

                # This is a version of the above which is more efficient
                # because it doesn't do the work needed to allow
                # recomposition:
                #
                fun get__substate me
                    =
                    {   my (state, substate) = super::get__substate me;
                        substate;
                    };

                # Finally, the three synthesized functions
                # which allow our subclasses to override
                # methods inherited from us.  'new_method'
                # is the method which is to replace the
                # existing one.  We pass the existing
                # method function to 'new_method' so that
                # it can use it if desired:
                #
                fun override__get  new_method  me
                    =
                    oop::repack_object
                        (fn (OBJECT__STATE { object__methods, object__fields })
                            =
                            OBJECT__STATE
                              { object__fields,
                                object__methods => { get       => new_method object__methods.get,       # Update this method.
                                                     increment =>            object__methods.increment, # Copy this method over unchanged.
                                                     reset     =>            object__methods.reset      # Copy this method over unchanged.
                                                   }
                              }
                        )
                        (super::unpack__object me);

                fun override__increment  new_method  me
                    =
                    oop::repack_object
                        (fn (OBJECT__STATE { object__methods, object__fields })
                            =
                            OBJECT__STATE
                              { object__fields,
                                object__methods => { get       =>            object__methods.get,       # Copy this method over unchanged.
                                                     increment => new_method object__methods.increment, # Update this method.
                                                     reset     =>            object__methods.reset      # Copy this method over unchanged.
                                                   }
                              }
                        )
                        (super::unpack__object me);

                fun override__reset new_method me
                    =
                    oop::repack_object
                        (fn (OBJECT__STATE { object__methods, object__fields })
                            =
                            OBJECT__STATE
                              { object__fields,
                                object__methods => { get       =>            object__methods.get,       # Copy this method over unchanged.
                                                     increment =>            object__methods.increment, # Copy this method over unchanged. 
                                                     reset     => new_method object__methods.reset      # Update this method.
                                                   }
                              }
                        )
                        (super::unpack__object me);


            };                                  # package oop__internal

        # Import the contents of the above
        # package back into the main 'counter'
        # package, strong-sealed by the API.
        # This makes Full__State(X) fully abstract:
        #
        include oop__internal;

        # Remaining user code is left exactly as-is:
        # 
        fun new ()
            =
            make__object ((), ());
    };                                          # package counter
\end{verbatim}

As you can see, the fully expanded form of {\tt counter} is ten times longer 
than the class form;  while it is possible to implement Berthomieu's oop recipe 
entirely by hand, it is definitely nice to have the compiler do most of the 
busywork.

{\bf Subclassing}

Now we explore subclassing.  We will start with a very simple base 
class with two string-valued fields, plus two methods which return the 
values of those fields.  One field will have a value fixed by a declaration 
initializer, the other will have a value supplied at object creation time:

\begin{verbatim}
    #!/usr/bin/mythryl

    class test {

        field my  String  string_1a = "abc";
        field my  String  string_1b;

        message fun          Self(X) -> String
            get1a self
                =
                self->string_1a;

        message fun         Self(X) -> String
            get1b self
                =
                self->string_1b;

        fun new string_1b
            =
            make__object ({ string_1b }, ());
    };


    # Demonstration:
    print "\n";

    include test;

    object_a = new "ABC";
    object_b = new "XYZ";

    printf "get1a object_a == %s\n" (get1a object_a);
    printf "get1a object_b == %s\n" (get1a object_b);

    printf "get1b object_a == %s\n" (get1b object_a);
    printf "get1b object_b == %s\n" (get1b object_b);
\end{verbatim}

When run this produces:

\begin{verbatim}
    linux$ ./my-script

    get1a object_a == abc
    get1a object_b == abc
    get1b object_a == ABC
    get1b object_b == XYZ
\end{verbatim}

Points to note:

\begin{itemize}
\item All instances of class {\tt test} will have the same value for field 
      {\tt string\_1a}, because it is assigned a constant value in its declaration. 
\item Differentinstances of class {\tt test} may have different values for field 
      {\tt string\_1b}, because it is assigned its value at object creation time. 
\item {\tt make\_\_object} takes a tuple of {\tt N} initialization records, 
      one for each class in the class hierarchy.  Every class without an explicitly 
      specified parent is a subclass of class {\tt object}, so this class has a 
      two-deep class hierarchy, itself and its sole superclass, {\tt object}. 
\item {\tt make\_\_object} must initialize every object field at creation time, so every field 
      which has no declaration initializer must be supplied a value in the initialization 
      record.  In this case, class {\tt object} has no such fields and class {\tt test} 
      has one, {\tt string\_1b} so {\tt make\_\_object} needs only one initializer. 
\end{itemize}

Now we subclass the above class.  Let us start by making a careful distinction 
between {\it message} and {\it method}:

\begin{itemize}
\item A {\it message} is an element of the class client interface;  it defines 
      a window onto objects of that class, including all objects of all subclasses.
\item A {\it method} is an function internal to a particular class which 
      implements a particular message defined for that class.
\end{itemize}

A message is defined once by some class, with that definition inherited by 
all subclasses of that class.  Subclasses may however provide their own 
methods to implement that message.

Mythryl distinguishes carefully between defining a new message and defining 
a new method for an existing message;  it uses different syntax for the two.

The {\tt message fun} declarations shown in the above examples both define a 
message and provide a default method for it.

The {\tt method fun} declarations shown below do not define messages;  instead 
they provide replacement methods for messages inherited from their superclass. 
A {\tt method fun} declaration does not include a type declaration;  the required 
type information is obtained from the original {\tt message fun} declaration.

\begin{verbatim}
    #!/usr/bin/mythryl

    class test_class {

        field my  String  string_1a = "1a";
        field my  String  string_1b;

        message fun          Self(X) -> String
            get1a self
                =
                self->string_1a;

        message fun         Self(X) -> String
            get1b self
                =
                self->string_1b;

        fun new string_1b
            =
            make__object ({ string_1b }, ());
    };


    class test_subclass {

        class super = test_class;               # Select test_class as our parent class.

        field my  String  string_2a = "2a";    # Define two new fields of our own.
        field my  String  string_2b;

        message fun          Self(X) -> String  # Define message to access our first field.
            get2a self
                =
                self->string_2a;

        message fun         Self(X) -> String   # Define message to access our second field.
            get2b self
                =
                self->string_2b;

        method fun                              # Override inherited method for test_class::get1a message.
            get1a old_method self
                =
                "<" + (old_method self) + ">";  # Return same result as old method, but wrapped in angle brackets.

        method fun                              # Override inherited method for test_class::get1b message.
            get1b old_method self
                =
                "<" + (old_method self) + ">";


        fun new string_2b string_1b
            =
            make__object ({ string_2b }, { string_1b }, ());
    };


    # Demonstration:


    object_10 = test_class::new "1b-10";
    object_11 = test_class::new "1b-11";

    object_20 = test_subclass::new "2b-20" "1b-20";
    object_21 = test_subclass::new "2b-21" "1b-21";

    print "\n";
    printf "get1a object_10 == %s\n" (test_class::get1a object_10);
    printf "get1a object_11 == %s\n" (test_class::get1a object_11);
    printf "get1a object_20 == %s\n" (test_class::get1a object_20);
    printf "get1a object_21 == %s\n" (test_class::get1a object_21);

    print "\n";
    printf "get1b object_10 == %s\n" (test_class::get1b object_10);
    printf "get1b object_11 == %s\n" (test_class::get1b object_11);
    printf "get1b object_20 == %s\n" (test_class::get1b object_20);
    printf "get1b object_21 == %s\n" (test_class::get1b object_21);

    print "\n";
    printf "get2a object_20 == %s\n" (test_subclass::get2a object_20);
    printf "get2a object_21 == %s\n" (test_subclass::get2a object_21);

    print "\n";
    printf "get2b object_20 == %s\n" (test_subclass::get2b object_20);
    printf "get2b object_21 == %s\n" (test_subclass::get2b object_21);
\end{verbatim}

When run this produces:

\begin{verbatim}
    linux$ ./my-script

    get1a object_10 == 1a
    get1a object_11 == 1a
    get1a object_20 == <1a>
    get1a object_21 == <1a>

    get1b object_10 == 1b-10
    get1b object_11 == 1b-11
    get1b object_20 == <1b-20>
    get1b object_21 == <1b-21>

    get2a object_20 == 2a
    get2a object_21 == 2a

    get2b object_20 == 2b-20
    get2b object_21 == 2b-21
\end{verbatim}

Points to note:
\begin{itemize}
\item Use {\tt class super = ... } lines to identify the superclass. Maximum one per class. 
\item {\tt test\_subclass} may not use {\tt self->string\_1a} notation to access {\tt test\_class} fields. 
      A subclass may directly access only its own fields, not those of any superclass.  (In 20/20 hindsight, 
      it is clear that a deficiency of classical oop is lack of proper modularity at class/subclass boundaries; 
      this is why deep inheritance hierarchies are unmaintainable in those languages.)  Subclass field names need not be 
      distinct from those of superclasses;  they live in different namespaces.  
\item The first argument of a {\tt method fun} is the inherited method being overridden.  This allows 
      the new method to make use of the old method.  There is no other mechanism for accessing the old 
      method.
\item {\tt test\_subclass} has a two-deep superclass chain ({\tt test\_class} then {\tt object}) so its 
      synthesized {\tt make\_\_object} function takes as argument a tuple of three initialization records, 
      one each for {\tt test\_subclass},  {\tt test\_class} and  {\tt object}.
\end{itemize}

{\bf Object equality}

Now let us consider object equality.  Class {\tt object} defines an {\tt equal} message 
which may be used to compare pairs of objects for equality.  In general any class which 
adds new state and which is going to be compared for equality probably wants to override 
the inherited {\tt equal} method with one which takes the added state into account.
Here is an example:

\begin{verbatim}
    #!/usr/bin/mythryl

    class test_class {

        field my  String  string1;

        method fun                         # Self(X) -> Self(X) -> Bool
            equal old_method a b
                =
                a->string1 == b->string1;       # Ignore inherited method; test_class instances are equal if their string1 fields are.

        fun new string1
            =
            make__object ({ string1 }, ());
    };


    class test_subclass {

        class super = test_class;

        field my  String  string2;

        method fun          # Self(X) -> Self(X) -> Bool
            equal superclass_equal a b
                =
                (superclass_equal a b)          # Require that inherited equality method return TRUE.
                and
                a->string2 == b->string2;       # Require in addition that our own string2 fields compare equal.

        fun new string1 string2
            =
            make__object ({ string2 }, { string1 }, ());
    };


    # Demonstration:


    object_1a = test_class::new "a";
    object_1b = test_class::new "b";

    object_2aa = test_subclass::new "a" "a";
    object_2ab = test_subclass::new "a" "b";
    object_2ba = test_subclass::new "b" "a";
    object_2bb = test_subclass::new "b" "b";

    print "\n";
    printf "object::equal object_1a object_1a == %B\n" (object::equal object_1a object_1a);
    printf "object::equal object_1a object_1b == %B\n" (object::equal object_1a object_1b);
    printf "object::equal object_1b object_1b == %B\n" (object::equal object_1b object_1b);

    print "\n";
    printf "object::equal object_2aa object_2aa == %B\n" (object::equal object_2aa object_2aa);
    printf "object::equal object_2aa object_2ab == %B\n" (object::equal object_2aa object_2ab);
    printf "object::equal object_2aa object_2ba == %B\n" (object::equal object_2aa object_2ba);
    printf "object::equal object_2aa object_2bb == %B\n" (object::equal object_2aa object_2bb);

    printf "object::equal object_2ab object_2aa == %B\n" (object::equal object_2ab object_2aa);
    printf "object::equal object_2ab object_2ab == %B\n" (object::equal object_2ab object_2ab);
    printf "object::equal object_2ab object_2ba == %B\n" (object::equal object_2ab object_2ba);
    printf "object::equal object_2ab object_2bb == %B\n" (object::equal object_2ab object_2bb);

    printf "object::equal object_2ba object_2aa == %B\n" (object::equal object_2ba object_2aa);
    printf "object::equal object_2ba object_2ab == %B\n" (object::equal object_2ba object_2ab);
    printf "object::equal object_2ba object_2ba == %B\n" (object::equal object_2ba object_2ba);
    printf "object::equal object_2ba object_2bb == %B\n" (object::equal object_2ba object_2bb);

    printf "object::equal object_2bb object_2aa == %B\n" (object::equal object_2bb object_2aa);
    printf "object::equal object_2bb object_2ab == %B\n" (object::equal object_2bb object_2ab);
    printf "object::equal object_2bb object_2ba == %B\n" (object::equal object_2bb object_2ba);
    printf "object::equal object_2bb object_2bb == %B\n" (object::equal object_2bb object_2bb);
\end{verbatim}

When run this produces:

\begin{verbatim}
    linux$ ./my-script

    object::equal object_1a object_1a == TRUE
    object::equal object_1a object_1b == FALSE
    object::equal object_1b object_1b == TRUE

    object::equal object_2aa object_2aa == TRUE
    object::equal object_2aa object_2ab == FALSE
    object::equal object_2aa object_2ba == FALSE
    object::equal object_2aa object_2bb == FALSE
    object::equal object_2ab object_2aa == FALSE
    object::equal object_2ab object_2ab == TRUE
    object::equal object_2ab object_2ba == FALSE
    object::equal object_2ab object_2bb == FALSE
    object::equal object_2ba object_2aa == FALSE
    object::equal object_2ba object_2ab == FALSE
    object::equal object_2ba object_2ba == TRUE
    object::equal object_2ba object_2bb == FALSE
    object::equal object_2bb object_2aa == FALSE
    object::equal object_2bb object_2ab == FALSE
    object::equal object_2bb object_2ba == FALSE
    object::equal object_2bb object_2bb == TRUE
\end{verbatim}

{\bf Defining a new binary message}

Finally, let us demonstrate defining and using a new binary message. 
We define a simple class which contains a single string field, together 
with a binary message {\tt concatenate} which returns the contatenation of the strings from 
two objects of that class, then we define a subclass with an additional 
string field which overrides the {\tt concatenate} method to include its 
own fields in the result:

\begin{verbatim}
    #!/usr/bin/mythryl

    class test_class {

        field my  String  string;

         message fun
             Self(X) -> Self(X) -> String
             concatenate a b
                 =
                 a->string + b->string;

        fun new string
            =
            make__object ({ string }, ());
    };


    class test_subclass {

        class super = test_class;

        field my  String  string;

        method fun
            concatenate superclass_method a b
                =
                (superclass_method a b)
                + "," +
                (a->string + b->string);

        fun new string1 string2
            =
            make__object ({ string => string2 }, { string => string1 }, ());
    };


    # Demonstration:

    object_1a = test_class::new "a";
    object_1b = test_class::new "b";

    object_2ca = test_subclass::new "c" "a";
    object_2cb = test_subclass::new "c" "b";
    object_2da = test_subclass::new "d" "a";
    object_2db = test_subclass::new "d" "b";

    print "\n";
    printf "test_class::concatenate object_1a object_1a == %s\n" (test_class::concatenate object_1a object_1a);
    printf "test_class::concatenate object_1a object_1b == %s\n" (test_class::concatenate object_1a object_1b);
    printf "test_class::concatenate object_1b object_1b == %s\n" (test_class::concatenate object_1b object_1b);

    print "\n";
    printf "test_class::concatenate object_2ca object_2ca == %s\n" (test_class::concatenate object_2ca object_2ca);
    printf "test_class::concatenate object_2ca object_2cb == %s\n" (test_class::concatenate object_2ca object_2cb);
    printf "test_class::concatenate object_2ca object_2da == %s\n" (test_class::concatenate object_2ca object_2da);
    printf "test_class::concatenate object_2ca object_2db == %s\n" (test_class::concatenate object_2ca object_2db);

    printf "test_class::concatenate object_2cb object_2ca == %s\n" (test_class::concatenate object_2cb object_2ca);
    printf "test_class::concatenate object_2cb object_2cb == %s\n" (test_class::concatenate object_2cb object_2cb);
    printf "test_class::concatenate object_2cb object_2da == %s\n" (test_class::concatenate object_2cb object_2da);
    printf "test_class::concatenate object_2cb object_2db == %s\n" (test_class::concatenate object_2cb object_2db);

    printf "test_class::concatenate object_2da object_2ca == %s\n" (test_class::concatenate object_2da object_2ca);
    printf "test_class::concatenate object_2da object_2cb == %s\n" (test_class::concatenate object_2da object_2cb);
    printf "test_class::concatenate object_2da object_2da == %s\n" (test_class::concatenate object_2da object_2da);
    printf "test_class::concatenate object_2da object_2db == %s\n" (test_class::concatenate object_2da object_2db);

    printf "test_class::concatenate object_2db object_2ca == %s\n" (test_class::concatenate object_2db object_2ca);
    printf "test_class::concatenate object_2db object_2cb == %s\n" (test_class::concatenate object_2db object_2cb);
    printf "test_class::concatenate object_2db object_2da == %s\n" (test_class::concatenate object_2db object_2da);
    printf "test_class::concatenate object_2db object_2db == %s\n" (test_class::concatenate object_2db object_2db);
\end{verbatim}

When run this yields:

\begin{verbatim}
    linux$ ./my-script

    test_class::concatenate object_1a object_1a == aa
    test_class::concatenate object_1a object_1b == ab
    test_class::concatenate object_1b object_1b == bb

    test_class::concatenate object_2ca object_2ca == cc,aa
    test_class::concatenate object_2ca object_2cb == cc,ab
    test_class::concatenate object_2ca object_2da == cd,aa
    test_class::concatenate object_2ca object_2db == cd,ab
    test_class::concatenate object_2cb object_2ca == cc,ba
    test_class::concatenate object_2cb object_2cb == cc,bb
    test_class::concatenate object_2cb object_2da == cd,ba
    test_class::concatenate object_2cb object_2db == cd,bb
    test_class::concatenate object_2da object_2ca == dc,aa
    test_class::concatenate object_2da object_2cb == dc,ab
    test_class::concatenate object_2da object_2da == dd,aa
    test_class::concatenate object_2da object_2db == dd,ab
    test_class::concatenate object_2db object_2ca == dc,ba
    test_class::concatenate object_2db object_2cb == dc,bb
    test_class::concatenate object_2db object_2da == dd,ba
    test_class::concatenate object_2db object_2db == dd,bb
\end{verbatim}

So far, so good.  Unfortunately, now we hit a roadblock;  Berthomieu's appendix 
A2.3.2 "simple dynamic dispatch" approach effectively requires that all objects 
in a given method call belong to the same class.  This makes it quite difficult 
to implement objects which contain objects of other classes, and more generally 
dynamic heterogeneous object hierarchies.

This is a serious deficiency; it rules out probably at least 
half of the potential applications for Mythryl oop.

Berthomieu gives a solution to this in appendix A2.3.3 of his paper, involving 
"folding" (wrapping) objects to hide their types from the type system in this 
situation.  Implementing that looks like the next logical step on the Mythryl 
oop front.

{\bf Source Code}

Oop functionality is implemented by 
\ahrefloc{src/lib/compiler/front/typer/main/expand-oop-syntax.pkg}{src/lib/compiler/front/typer/main/expand-oop-syntax.pkg}, 
with assists from  
\ahrefloc{src/lib/compiler/front/typer/main/expand-oop-syntax-junk.pkg}{src/lib/compiler/front/typer/main/expand-oop-syntax-junk.pkg}, 
\ahrefloc{src/lib/compiler/front/typer/main/oop-collect-methods-and-fields.pkg}{src/lib/compiler/front/typer/main/oop-collect-methods-and-fields.pkg} 
and 
\ahrefloc{src/lib/compiler/front/typer/main/oop-rewrite-declaration.pkg}{src/lib/compiler/front/typer/main/oop-rewrite-declaration.pkg}.  The 
main point of invocation is from {\tt typecheck\_named\_packages} in 
\ahrefloc{src/lib/compiler/front/typer/main/type-package-language-g.pkg}{src/lib/compiler/front/typer/main/type-package-language-g.pkg}.

{\bf Conclusion}

When in doubt, it makes sense to try the simplest solution first.

Berthomieu's oop approach provides the simplest solution I know of for the 
problem of providing basic object oriented programming support in Mythryl.

Whether this approach will prove adequate in practice is not yet clear to me.

This facility should currently be regarded as highly experimental and 
subject to change or deletion in future releases.

\cutend*


% --------------------------------------------------------------------------------
\subsection{Pre-Compile Code}
\cutdef*{subsubsection}
\label{section:tut:full-monte:pre-compile-code}

The Mythryl compiler supports a simple hack to allow executing short 
fragments of code at compiletime, just before a file is compiled: 

\begin{verbatim}
    #DO set_control "compiler::verbose_compile_log" "TRUE";
\end{verbatim}

As illustrated, the main intended use for this facility is to set 
compiler switches.  (Setting the illustrated switch at the top of 
a {\tt foo.pkg} file will result in verbose compile logging into 
{\tt foo.pkg.compile.log}.)  A full list of available switches and their 
current settings may be obtained by executing {\tt show\_controls()} 
at the interactive prompt:

\begin{verbatim}
    linux% my

    Mythryl 110.58.4.2.3 built Tue Sep 13 00:48:57 2011
    Do   help();   for help.

    eval:  show_controls();
      Compiler controls:
       tracing/debugging/profiling:
             tdp::instrument = FALSE
       makelib:
             makelib::verbose = TRUE
             makelib::debug = FALSE
       ...

    eval:  
\end{verbatim}

More than one {\tt #DO} statement may be included in a file;  the 
compiler will evaluate them in order of appearance.

Very few of these are of current use, or even documented;  two of the 
most useful applications of {\tt #DO} are enabling integer overflow 
trapping when desired (next section) and 
disabling vector and matrix index bounds-checking when not desired 
(section after that).

The current implementation of {\tt #DO} is something of a kludge;  in 
particular the lexer simply scans until it reaches a semicolon, which 
means the code to be executed cannot contain a semicolon internally, 
even in a quoted string (say).  Currently it can also not contain a newline.
For the intended purpose this is not  a problem;  if it becomes a problem,
the lexer code can be upgraded. 

The {\tt #DO} statement syntax is supported only at top level;  it 
will not be recognized inside of a package or such.  Also, no matter 
where in the file a {\tt #DO} statement is located, it will always 
be evaluated before compiling any code in the file.  To avoid confusion, 
it is best to place such statements at the top of the source file, 
before the main api or package code to be compiled.

\cutend*


% --------------------------------------------------------------------------------
\subsection{Int Overflow Checking}
\cutdef*{subsubsection}
\label{section:tut:full-monte:int-overflow-checking}

The {\tt SML/NJ} compiler traps integer overflow by default, but 
the Mythryl compiler does not, because this can slow down integer 
code by twenty percent or more.  Integer overflow trapping can be enabled 
within a given sourcefile by putting the line 

\begin{verbatim}
    #DO set_control "compiler::trap_int_overflow" "TRUE";
\end{verbatim}

near the top of the file; any overflows during integer computations 
will then result in the {\tt OVERFLOW} exception being raised. 

If you want int overflow checking to be the default, you can change 

\begin{verbatim}
        trap_int_overflow       = make_control (b, "trap_int_overflow",   "?", FALSE);
\end{verbatim}

to 

\begin{verbatim}
        trap_int_overflow       = make_control (b, "trap_int_overflow",   "?", TRUE);
\end{verbatim}

in  \ahrefloc{src/lib/compiler/toplevel/main/compiler-controls.pkg}{src/lib/compiler/toplevel/main/compiler-controls.pkg} 
and recompile the compiler.

\cutend*


% --------------------------------------------------------------------------------
\subsection{Vector Index Bounds Checking}
\cutdef*{subsubsection}
\label{section:tut:full-monte:vector-index-bounds-checking}

The Mythryl compiler by default on every vector-slot get or set checks the index 
to make sure it is in bounds.  If the index is not both non-negative and less 
than the length of the vector the {\tt INDEX_OUT_OF_BOUNDS} exception is raised.  This 
prevents heap-corruption bugs but it also slows down vector-intensive code by 
more than a factor of two. 

Vector index bounds checking can be disabled 
within a given sourcefile by putting the line 

\begin{verbatim}
    #DO set_control "compiler::check_vector_index_bounds" "FALSE";
\end{verbatim}

near the top of the file.

\textbf{Be very afraid} when using this control!  Use it only 
on code which is both thoroughly tested and debugged and also demonstrably 
speed critical.  Heap-corruption bugs are nasty enough in C, where the heap 
is simple and static;  to corrupt the Mythryl heap, which is complex and 
highly dynamic, is to enter a whole new \textbf{world of pain}. 

\cutend*


% --------------------------------------------------------------------------------
\subsection{Summary}
\cutdef*{subsubsection}

Becoming literate in English means not merely knowing the alphabet and grammar, 
but knowing the vocabulary, and the major works of literature in the language.

Much the same is true of a programming language.  Learning the lexical syntax, 
the grammar, and the language semantics is a good beginning, but to be truly 
proficient in the language you need to also be familiar with a variety of 
standard libraries.

You now have a reasonable grasp of the Mythryl syntax and semantics;  it is 
time to start learning your way around the Mythryl standard libraries, which 
provide much of the functionality you need to code effectively in Mythryl. 

The \ahrefloc{section:indices:api}{Api Index} is a good place to start your browsing.

\cutend*

