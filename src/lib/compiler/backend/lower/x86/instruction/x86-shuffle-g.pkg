## x86-shuffle-g.pkg
#

# Compiled by:
#     src/lib/compiler/backend/lower/make7/ia32.make6



#               "I think we need someone in a
#                responsible political position
#                to have the courage to say,
#                'Let's terminate human spaceflight.'"
#
#                              --James Van Allen 


# We are invoked from:
#
#     src/lib/compiler/codegen/x86/x86-codetree.pkg

generic package x86_shuffle_g (

    instruction_set:  Instruction_Set_X86			# Instruction_Set_X86	is from   src/lib/compiler/backend/lower/x86/instruction/instruction-set-x86.api

)

: (weak) Xy86Shuffle						# Xy86Shuffle	is from   src/lib/compiler/backend/lower/x86/instruction/x86-shuffle.api

{
    package instruction_set = instruction_set;
    package cells           = instruction_set::cells;

    package shuffle         = shuffle_g( instruction_set );	# shuffle_g	is from   src/lib/compiler/backend/lower/instruction/shuffle-g.pkg

    package i = instruction_set;
    package c = cells;
    package cb= cells_basis;					# cells_basis	is from   src/lib/compiler/backend/lower/instruction/cells-basis.pkg

    Type = { tmp:  Null_Or( i::Operand ),
             dst:  List( cells_basis::Cell ),
             src:  List( cells_basis::Cell )
           };

    exception FOO;

    shuffle
        =
        shuffle::shuffle {
	    mv_instr =>   fn { dst, src } => [i::move { mv_op=>i::MOVL, src, dst } ]; end ,
	    ea      =>   i::DIRECT
        };

    # These assume that the ''registers''
    # are mapped onto the memory.

    # Note, this only works with
    # double precision floating point:
    #
    shufflefp_normal_and_slow
	= 
	shuffle::shuffle {
	    mv_instr =>   fn { dst, src } = [i::fldl src, i::fstpl dst],
	    ea       =>   i::FDIRECT
	};

    # This version makes use of the x86
    # floating point stack for hardware
    # renaming:
    #
    fun shufflefp_normal { tmp, src, dst }
	=
	{   n =  length src;

	    if (n <= 7)
	        
		 fun gen (s ! ss, d ! ds, pushes, pops)
			 => 
			 if   (cb::same_color (s, d))
			     
			      gen (ss, ds, pushes, pops);
			 else 
			      gen (ss, ds, 
				  i::fldl  (i::FDIRECT s) ! pushes,
				  i::fstpl (i::FDIRECT d) ! pops
			      );
			 fi;

		     gen (_, _, pushes, pops)
			 =>
			 list::reverse_and_prepend (pushes, pops);
		 end;

		 gen (src, dst, [], []); 

	    else
		 shufflefp_normal_and_slow { tmp, src, dst };
	    fi;
	};

    # These assume that the ''registers'' are mapped onto the pseudo 
    # %fpr register.  Only works with double precision floating point for 
    # now...
    #
    shufflefp_fast
        = 
	shuffle::shuffle {
	    mv_instr =>   fn { dst, src } = [i::fmove { fsize => i::FP64,   src, dst } ],
	    ea       =>   i::FPR
        };

    fun shufflefp (x as { tmp=>THE (i::FPR _), ... } )
            =>
            shufflefp_fast x;

        shufflefp x
            =>
            shufflefp_normal x;
    end;

};

# NOTE on xchg on the x86
#
# From Allen Leung:
# Here's why I didn't use xchg: 
# 
# o  According to the optimization guide xchg mem, reg is complex,
#    cannot be pipelined or paired at all. xchg reg, reg requires 3 uops.
#    In contrast, mov mem, reg requires 1 or 2 uops.  
#    So xchgs loses out, at least on paper.  
#    [I haven't done any measurements though] 
# 
# o  Secondly, unlike other architectures, parallel copies are split 
#    into individual copies during instruction selection.  Here's why
#    I did this:  I found that more copies are retained and more spills 
#    are generated when keeping the parallel copies.   My guess on this is 
#    that the copy temporary for parallel copies create addition 
#    interferences [even when they are not needed.]  
#    This is not a problem on RISC machines, because of plentiful registers.
#   
# o  Spilling of parallel copies is also a very complex business when
#    memory coalescing is turned on.  I think I have implemented a solution
#    to this, but not using parallel copies keep life simple.   This problem
#    could be simpler with xchg...but I haven't thought about it much.
# 
# From Fermin Reig:
# In the java@gcc.gnu.org, GC  mailing lists there's been a discussion about
# the costs of xcgh. Here's some extracts of it:
# 
# ----------------
# > From: Emery Berger [mailto: emery@cs.utexas.edu]
# > 
# > http://developer.intel.com/design/pentium4/manuals/24547203::pdf
# > 
# > See Chapter 7.1. "For the P6 family processors, locked 
# > operations serialize
# > all outstanding load and store operations (that is, wait for them to
# > complete). This rule is also TRUE for the Pentium 4 
# > processor, with one
# > exception: load operations that reference weakly ordered 
# > memory types (such
# > as the WC memory type) may not be serialized. "
# > 
# -----------------
# I just tried this on a 500 MHz Pentium III.  I get about 23 cycles for
#  
# lock; cmpxchg
#  
# :
# and about 19 or 20 cycles for xchg (which has an implicit lock prefix).
#  
# I got consistent results by timing a loop and by looking at an instruction
# level profile.  Putting other stuff in the loop didn't seem to affect the
# time taken by xchg much.  Here's the code in case someone else wants to try.
# (This requires Linux/gcc)
# -------------------
# Chris Dodd pointed out on the GC mailing list that on recent Intel X86
# processors:
#  
# - cmpxchg without a lock prefix is much faster (roughly 3x or close to 15
# cycles by my measurements) than either xchg (implied lock prefix) or lock;
# cmpxchg .
#  
# - cmpxchg without the lock prefix is atomic on uniprocessors, i.e. it's not
# interruptable.
#  
# As far as I can tell, none of the GNU libraries currently take advantage of
# this fact.  Should they?
#  
# This argues, for example, that I could get noticable additional speedup from
# Java hash synchronization on X86 by overwriting a few strategic "lock"
# prefixes with "nop"s when I notice that there's only one processor
#
#
# From John Reppy:
#
# Disregard what I said.  The xchg instruction has an implicit lock prefix,
# so it is not useful for normal programming tasks.
